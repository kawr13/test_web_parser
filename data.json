[{'header': 'Как я проектирую и разрабатываю расширения Python на Rust', 'text': ['Вы наверняка видели множество статей на тему "Python, Rust - производительность, бла-бла-бла... Вот, реализуем foo2plus2". Вся беда в том, что все эти статьи демонстрируют очень простые примеры уровня "hello-world". Напротив, в этой статье я хочу рассказать о том, как я проектирую комплексные расширения и почему я принимаю те или иные проектные решения.', 'Статья является переводом и адаптацией моей же статьи на Medium. Возможно, кто-то предпочтет прочесть в оригинале - ссылка позволяет прочитать без подписки.', 'На данный момент я написал четыре библиотеки для Python на Rust (1,\xa02,\xa03,\xa04) и приобрел определенный опыт, но все еще не чувствую, что достиг той квалификации, которая позволяет утверждать, что правильно, а что нет. Некоторые из моих подходов вдохновлены другими людьми, другие являются результатом анализа и долгих попыток рефакторинга кода, и все же, я не уверен, что мои решения являются лучшими из возможных.', 'Кроме того, я не очень опытный разработчик на Rust, поэтому в моем коде могут встречаться забавные вещи - будьте готовы к фейспалмам, если вы сильно прошарены в Rust.', 'Если порыться в моих репозиториях, то можно обнаружить эволюцию подхода к разработке расширений Rust для Python: например, в Similari многие решения странные, но именно в ходе данного проекта у меня произошел существенный скачок вперед, когда я получил PR от Андрея Ткаченко.', 'Другая команда продемонстрировала, как использовать Sphinx для документирования расширений, и я написал об этом в соответствующей статье. Я провел несколько часов, погружаясь в среду Manylinux и особенности ее использование в Maturin GitHub Action, в результате чего появилась статья, демонстрирующая, как создавать переносимые расширения Rust для Python с помощью GitHub CI и сборке в Docker.', 'Хочу сказать "спасибо" всем тем, кто помог мне продвинуться в данной теме: все вы проделали огромную работу, создавая свой код без общепринятых подходов и обширной документации.', 'Благодарю следующие коллективы и людей за участие в моем прогрессе:', 'PyO3\xa0team\xa0— за их усилия по предоставлению разработчикам превосходного инструмента для  создания расширений Python на Rust;', 'Andrei Tkachenko\xa0— за демонстрацию возможностей использования transmute при разработке расширений Python на Rust и за огромный вклад в развитие Similari;', 'Pola.rs project\xa0team\xa0— идеи по дизайну и фрагменты кода;', 'Pometry/Raphtory\xa0team\xa0— за идеи по документированию расширений Python на Rust.', 'Это не вводная статья. Я предполагаю, что вы знаете Rust и можете написать расширение типа "hello world" для Python на Rust с помощью PyO3. Я предполагаю, что вы знаете, что такое GIL и как он работает.', 'Rust и Python подходят по разному к управлению памятью, что иногда превращает проектирование сложных структур данных и способов их взаимодействия между собой в нетривиальную задачу: в Rust модель памяти основана на владении, а в Python - на ссылках на объекты в куче. ', 'Наиболее близкой структурой, представляющей модель памяти Python, в Rust является:', 'Однако, в Python вышеуказанный мьютекс представлен GIL - глобальная блокировка, общая для всех объектов в рантайме, в то время как в Rust возможно осуществлять изолированную блокировку только нужных для работы объектов. ', 'Одна из ключевых проблем при проектировании объектной модели совместимой с Python заключается в том, что передать ссылку (&mut или &) из Rust в Python невозможно: для этого необходимо использовать Arc<T>. ', 'В PyO3 реализованы некоторые решения, позволяющие передавать аллоцированные в Python объекты в Rust-функции по ссылке, но обратная операция невозможна: вы не можете просто сохранить ссылку на Rust-объект в памяти Python. PyO3 поддерживает передачу объектов Rust в Python по значению, оборачивая их в объекты Python (PyObject).', 'Понимание моделей памяти и их особенностей их взаимодействия между собой важно для правильного проектирования кода, особенно если он освобождает GIL, поскольку освобождение GIL требует от объекта реализации трейта Ungil, который, по сути, является Send.', 'Если вы хотите одновременно использовать объект в Python и Rust, необходимо использовать обертку для него на базе Arc<T> или Arc<Mutex<T>>.', 'Пример объекта, используемого только в Python:', 'Ссылка на экземпляр данного класса может быть временно передана в функцию Rust, вызываемую из Python, например:', 'Или вы можете передать объект в Rust как копию (Clone) - объект в пространстве памяти Python не пропадет:', 'Пример объекта, используемого одновременно из Rust и Python:', 'Теперь вы можете иметь ссылки на один и тот же объект как в Python, так и в Rust, например:', 'Его можно одновременно использовать из Python и Rust (в двух потоках, например). Mutex<T> защищает его от гонки, а Arc<T> обеспечивает механизм совместного использования. Вместо мьютекса можно использовать другие примитивы синхронизации, например RwLock<T>.', 'Нельзя безопасно написать функцию, возвращающую в Python ссылку на объект, выделенный Rust. Но можно вернуть Python ссылку на объект, выделенный в памяти Python:', 'Сфера применения вышеуказанного кода ограничена, но можно, например, использовать для реализации билдеров или для реализации with.', 'При работе с PyO3, структура проекта сильно влияет на вашу производительность и удобство работы с кодом . Приступая к работе над расширением, вооружившись руководством по PyO3, вы обычно начинаете с проекта, сочетающего в себе как Rust-код, так и Python-аннотации, что приводит к тесной связи с Python - вы не сможете компилировать код без Python и тестировать его без инициализации среды выполнения Python.', 'В принципе, у вас есть два подхода к структурированию кода:', 'с использованием пространств имен и feature-флагов, размещая код, связанный с Python, за флагами (этот подход реализован в Similari);', 'с использованием отдельных крейтов, объединенных в одно рабочее пространство (Savant-RS, RocksQ).', 'Изначально я придерживался первого подхода, но сейчас считаю, что второй подход гораздо лучше. Вот как выглядит проект RocksQ в рамках подхода с разными крейтами:', 'Итак, как вы видите, у меня два крейта: в queue_rs я реализовал логику и функциональность, он ничего не знает о Python. Во втором - только код, связанный с Python. Я считаю, что такая компоновка является оптимальной по ряду причин. Давайте обсудим их.', 'Продуктивность при работе над кодом с логикой на Rust. Я хочу, чтобы мой код быстро компилировался и тестировался без использования среды исполнения Python и ее типов данных. Такая компоновка проекта позволяет разрабатывать код с логикой с использованием только нативных типов.', 'Зависимость от PyO3 увеличивает время компиляции и часто делает невозможной реализацию тестов без инициализации среды Python, что неудобно, и может приводить к инетересным эффектам, поскольку GIL сериализует код, ваши тесты могут приобретать неожиданное изменчивое от запуска к запуску поведение.', 'Например, при использовании PyBytes необходимо иметь рабочую среду Python для создания объекта данного типа. Я же не хочу иметь дело с этими лишними операциями при работе с логикой.', 'Следуя вышеизложенному, я пишу свой код с учетом особенностей модели памяти, но без типов, связанных с Python, и зависимости от PyO3.', 'Мои бенчмарки, размещенные в крейте с логикой, работают только с кодом на Rust, поэтому я уверен в том, что они проверяют скорость работы оптимизированного кода, а не транзакционные издержки, связанные с передачей данных между Python и Rust. В свою очередь, в крейте связи с Python вы можете размещать тесты, направленные на тестирование e2e поведения. ', 'Однажды с помощью такого подхода я выяснил, что передача в Rust больших массивов Vec<u8>  убивает производительность, и начал использовать PyBytes в своем коде, связанном с PyO3.', 'Продуктивность при работе над кодом, связанным с Python. Когда я работаю над кодом, связанным с Python, мне необходимо реализовывать только преобразование между типами Python и типами Rust, но не логику. Время компиляции уменьшается, поскольку крейте с логикой изменений не проиходит.', 'Особенно время компиляции беспокоит меня при работе над документацией - я очень часто меняю аннотации и перекомпилирую код для того, чтобы посмотреть как аннотации будут выглядеть после обработки Sphix. Мои соображения по созданию документации для расширений Rust читайте в соответствующей статье. Предложенная схема помогает мне значительно сократить время компиляции.', 'Структурирование кодовой базы. Я всегда знаю, где найти код - если он связан с Python, то в проекте *_py, в противном случае - в проекте *_rs. Это помогает уменьшить хаос, который возникает в случае, когда в одном файле встречается много кода, не относящегося к логике, но обеспечивающего взаимодействие с Python.', 'Именование объектов кода. Rust не поддерживает переопределения имен функций; обычно это означает, что если вам нужна одна и та же функция для внутренних целей (только для Rust) и для экспорта в Python, то одну из них требуется назвать как-то по-хитрому.', 'Раньше мне приходилось делать что-то в духе:', 'Это работает, но порождает беспорядочный код. В предлагаемом подходе это выглядит следующим образом:', 'Рано или поздно кто-то захочет получить сборку без Python. Так было с Similari, люди хотели получить код без зависимости от Python. Это стало проблемой. В результате Andrei Tkachenko предложил большой PR, поместив функциональность, связанную с Python, за feature-флаг.', 'Теперь, зная мой подход, вы, наверное, начали думать, что у меня дублируется больше кода, чем требуется. Да, это так, вместо аннотирования одного объекта с #[pyclass] у меня две реализации:', 'Тем не менее, я нахожу подход очень удобным, поскольку код в крейте *_py  является абсолютно шаблонным и легко генерируется GitHub Copilot практически без доработок.', 'Обычно я не использую традиционные структуры Rust в своих крейтах *_py : только кортежные структуры. Ранее я писал что-то вроде:', 'Однако теперь я вижу недостатки такой компоновки:', 'Я обнаружил, что иногда я использую "inner", иногда "object", "internal" и т.д. Это вносит хаос.', 'Код выглядит менее унифицированным, при кортежной компоновке обращение к внутреннему объекту всегда происходит через .0. .', 'Вы можете легко использовать std::mem::transmute 👿 с кортежеподобными структурами.', 'Для Option и Result можно использовать простую упаковку вида:', 'Магия transmute. Расположение в памяти X и struct Y(X) в Rust одинаково, поэтому с помощью transmute можно "безопасно" преобразовывать кортежные структуры Python в кортежные структуры Rust на месте, без перераспределения памяти. Особенно это актуально, когда необходимо преобразовать большой вектор (Vec<T>) между rust::Object и Python\'овским Object.', 'Не поймите меня неправильно, я не пропагандирую transmute - это небезопасная функция, но она может помочь преобразовать большие объекты памяти на месте практически без затрат.', 'Когда мне нужны такие перечисления, я дублирую их в двух крейтах и реализую в своем крейте *_py trait From для обоих направлений:', 'Честно говоря, эти перечисления не дают мне покоя. Такие перечисления прекрасно поддерживаются PyO3, и я могу просто использовать для них #[pyclass], но это требует либо переноса их в отдельный крейт с зависимостью от PyO3, либо добавления зависимости от PyO3 в мой крейт *_rs. На данный момент я решил остановиться на приведенном выше решении.', 'Возможно, стоит попробовать помещать их в отдельный крейт enums, который будет зависимостью для lib_rs и lib_py. Я еще не решил.', 'В настоящее время они не поддерживаются PyO3. Я работаю с ними так, как показано ниже, создавая отдельные объекты при возврате соответствующего варианта:', 'С помощью PyO3 можно легко преобразовать Rust Result (я использую anyhow) в Python PyResult, вариант  Err которого является Python-исключением:', 'Я очень часто использую Result в своем коде. Реализация в PyO3 очень элегантная: вы можете использовать модель кодирования Rust, которая прозрачно отображается на исключения в Python. Я нахожу это волшеным: если он возвращает Ok(smth), то получается обычное значение Python; если возвращает Err(e) - код Python вызывает исключение.', 'Python поддерживает аргументы по умолчанию, и я довольно часто использую их для упрощения API. Аргументы по умолчанию можно использовать в конструкторах, методах и функциях.', 'Конструкторы:', 'Методы (self пропускаем в описании сигнатуры):', 'Функции:', 'Обычно вы помечаете метод символом #[new], чтобы указать, что он используется как __init__ в Python. Если объект конструируется в Rust, вы можете вообще не иметь публично доступного конструктора. ', 'При построении перечислений я обычно использую несколько иной подход, основанный на #[staticmethod]. Вспомним наше перечисление Pet из предыдущего примера:', 'Теперь в языке Python объекты могут быть построены следующим образом:', 'Этот подход можно использовать и в том случае, если для регулярной структуры требуется несколько конструкторов, в зависимости от способа создания объекта.', 'Освобождение GIL не всегда является хорошей идеей. Когда код выполняется быстро, я не оптимизирую операции с GIL. Эмпирическим путем я обнаружил, что код обычно становится медленнее, если функция завершается быстрее, чем за 1000нс, и я освобождаю GIL внутри нее. Иногда я не уверен, нужно ли освобождать GIL или нет. В такой ситуации я реализую функцию, позволяя пользователю выбрать поведение:', 'Иногда, я добавляю еще трассировку тайминга работы с GIL, чтобы позже решить освобождать GIL или нет в конкретном случае.', 'Вы можете задаться вопросом, почему освобождение GIL может быть плохим вариантом? Позвольте мне объяснить это на примере псевдокода. Когда мы не освобождаем GIL, все работает следующим образом:', 'Когда освобождаем:', 'Видно, что операций ACQUIRE GIL две, а не одна, как могло бы сначала показаться. Каждая операция ACQUIRE GIL - это блокирующая операция захвата глобального мьютекса GIL, которая ожидает его доступности. При увеличении параллелизма это приводит к замедлению работы.', 'Просто имейте в виду, что когда ваш код вызвался, он уже готов к работе и уже потратил время на захват GIL. Я обычно освобождаю GIL только тогда, когда это повышает производительность параллелизма, а операции внутри функции занимают существенное время.', 'Раньше при работе с двоичными данными я использовал следующие конструкции (в PyO3 нельзя передавать &Vec<u8> или &[u8]):', 'Он медлителен при передаче больших байтовых буферов, однако дает гибкость: можно передавать Python bytes или [1, 2, 3]. В настоящее время при работе с большими двоичными данными я предпочитаю использовать &PyBytes (да, его можно передавать через &):', 'Вас не должно беспокоить, что внутри повторно захватывается GIL: поскольку он уже нам принадлежит, то захват мгновенный.', 'Обычно я помещаю функцию version() в пакет, чтобы легко проверять, что версия верна и соответствует ожидаемой. Обычно я проверяю версию в вызывающем коде, чтобы убедиться, что код на Python и Rust синхронизированы.', 'Довольно занудная штука - использовать это в каждой либе, но, как говорилось в рекламе: "Попробовал раз, ем и сейчас". Такой уж я человек :)', 'У PyO3 есть проблемы с вложенными пакетами Python. Погуглив и почитав обсуждения, я обнаружил, что следующий подход отлично работает:', 'В PyO3 используется отдельный крейт (pyo3-log), предоставляющий возможность направлять журналы Rust в систему протоколирования Python (из документации по PyO3):', 'Все выглядит просто замечательно до того момента, пока вы не поймете, что для этого необходимо получать GIL каждый раз, когда вы что-то логируете.', 'В своих проектах, когда это необходимо, я реализую обратную схему: Я предоставляю функцию log , реализованную на Rust в Python, а Python использует ее напрямую или реализует аппендер журнала для отправки своих сообщений в систему протоколирования Rust. Пример такого подхода к протоколированию можно посмотреть здесь.', 'Чтобы помочь пользователям разобраться во внутренней структуре объекта, вы можете предоставить им методы __repr__ и __str__ . Если ваша структура реализует трейт Debug, то вы можете использовать следующий подход:', 'Методы позволяют пользователю использовать стандартные подходы Python, чтобы понять структуру и состояние объекта.', 'Если вам необходимо, чтобы ваш объект использовался в качестве хэш-ключа, вам необходимо  предоставить реализацию для __hash__ :', 'Когда я хочу запретить использовать объекты в качестве ключей, я использую:', 'Я использовал эту механику только один раз в своих проектах, когда оборачивал векторы в объект для эффективной передачи между Rust и Python без дублирования памяти. В моем случае я имел следующую структуру:', 'Моя цель была в том, чтобы предоставить API для доступа к отдельным AttributeValue с помощью синтаксиса attribute_value[i]. Для того чтобы это стало возможным, необходимо реализовать две (только чтение) или три (чтение-запись) dunder-функции:', 'Если вам необходимо реализовать установку элемента, то вам также понадобится __setitem__ dunder:', 'Замечательно, что в PyO3 есть раздел, посвященный настройкам классов, где можно найти и другие полезные функции.', 'Долгое время я пытался найти подход к документированию расширений, чтобы помочь пользователям наблюдать только те части, которые доступны в Python, не заглядывая в исходный код Rust.', 'Исчерпывающее руководство по документированию таких расширений с помощью Sphinx вы найдете в моей отдельной статье. Я не публикую его здесь, чтобы сэкономить размер статьи.', 'При использовании нативных расширений нельзя просто установить с произвольной версией Python. Расширение должно быть собрано и слинковано с нужными версиями заранее или на этапе установки. Для автоматизации этого процесса можно использовать систему сборки с помощью Docker и GitHub Actions (или другой системы CI/CD).', 'Руководство по сборке таких расширений с помощью GitHub Actions вы найдете в моей отдельной статье. Я не публикую его здесь, чтобы сэкономить размер статьи.', 'Я подготовил небольшой проект RocksQ (персистентная очередь на основе RocksDB), в котором можно найти много вещей, реализованных в соответствии с моим руководством.', 'Я надеюсь, что это руководство поможет вам писать расширения для Python на Rust с меньшими трудностями и высокой производительностью. Если у вас есть свои советы и рекомендации, идеи и соображения, я буду рад их услышать.', '', 'Техдиректор в дикой природе', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}, {'header': 'Функциональное программирование в Python: ежедневные рецепты', 'text': ['Инженер-программист', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}, {'header': 'Многопоточность в Python: очевидное и невероятное', 'text': ['В данной статье я покажу на практическом примере как устроена многопоточность в Python, расскажу про потоки, примитивы синхронизации и о том зачем они нужны.', 'Изначально я планировал что это будет простая и короткая заметка, но пока готовил и тестировал код нашел интересный неочевидный момент связанный с внутренностями CPython, так что не спешите закрывать вкладку, даже если уверены что знаете о потоках в Python всё :)', 'Представим что нам в программе нужен счетчик. Казалось бы, ничего сложного:', 'Изменять счетчик мы планируем из независимых потоков, каждый поток изменяет значение счетчика X раз', 'Функция “main” выглядит так:', 'Вопрос: какое значение счетчика выведет программа?', 'Результат зависит от версии Python на которой был запущен скрипт.', 'Когда я в первый раз запустил эту программу я был ошарашен результатами, я был уверен на 100% что увижу в консоли противоположный результат. Результат выполнения скрипта на Python 3.11.5:', 'CPython неведомым способом смог обеспечить атомарность небезопасной по умолчанию операции increment.', 'Как он это сделал?  Давайте разбираться.', 'Перед тем как погружаться в детали реализации стандартной библиотеки и внутренностей рантайма я решил проверить поведение программы на других версиях языка. В этом мне здорово помогла утилита pyenv', 'Скрипт автоматизирующий выполнение программы на разных версиях Python', 'Результаты:', 'Почему в одних версиях Python значение счетчика совпадает c ожидаемым а в других нет? Всему виной состояние гонки.', 'Почему с нашим счетчиком возникает операция гонки? Всё дело в том что операция increment состоит из нескольких шагов:', 'прочитать значение (currVal = self.val)', 'увеличить (newVal =currVal  + 1)', 'записать новое значение (self.val = newVal)', 'И переключение контекста между потоками может произойти после шага 1 или шага 2 , что приведет к тому что поток перед выполнением шага 3 будет иметь в своем распоряжении невалидные данные.', 'Можно ли сделать вывод что в Python 3.10 избавились от race condition и нам не нужны примитивы синхронизации? Как бы не так :)', 'Проведя небольшое расследование я нашел вот такой коммит и сообщение в твиттере от Python Core Developer.', 'Рассмотрим альтернативную реализацию  счетчика, отличающуюся от обычной одной строчкой:', 'И запустим тесты:', 'Видим, что такой код ломает потокобезопасность даже на последних версиях Python.', 'Мы попробовали разные реализации и разные версии Python и везде были свои проблемы. Поэтому чтобы быть точно уверенными в счетчике то нам необходимо добавить в него синхронизацию, чтобы избавиться от гонки за данные:', 'Результаты', 'На этот раз без сюрпризов :)', 'В данной статье я постарался показать на простом примере как работают потоки, что такое состояние гонки и как синхронизация помогает его избегать а также рассказал про любопытную баг-фичу которую обнаружил в процессе написания статьи.', 'Если вы хотите поэкспериментировать самостоятельно то я опубликовал весь код из статьи на GitHub.', 'Спасибо что прочитали до конца, надеюсь что вам было интересно!', 'Полезные ссылки:', 'What kinds of global value mutation are thread-safe?', 'Context Switch Interval In Python', '', 'Senior Software Engineer', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}, {'header': '10 лучших практик логирования в Python', 'text': ['По мере того как приложение собирает все больше данных, правильное ведение журналов становится решающим фактором для быстрого и эффективного понимания общей функциональности. Это позволяет устранять проблемы до того, как они повлияют на конечных пользователей.', 'В этой статье мы рассмотрим лучшие практики логирования в Python. Следуя им, вы сможете обеспечить информативность, практичность и масштабируемость генерируемых логов. Давайте начнём!', 'Если вы нашли ошибку, пожалуйста, используйте Ctrl+Enter и я исправлю. Спасибо!', '', 'Корневой логгер - это регистратор по умолчанию в модуле logging. Хотя использование корневого логгера может быть заманчивым для упрощения кода, есть несколько причин, по которым его следует избегать:', 'Отсутствие контроля: При использовании корневого логгера вы имеете ограниченный контроль над тем, как обрабатываются сообщения журнала. Это может привести к проблемам, связанным с отправкой сообщений журнала в неожиданные места или неправильной установкой уровней журнала.', 'Сложность управления регистраторами: При использовании корневого регистратора может возникнуть проблема управления несколькими регистраторами в сложном приложении. Это может привести к проблемам, связанным с дублированием сообщений журнала или неправильной настройкой регистраторов.', 'Невозможность разделения данных журнала: Корневой логгер является общим для всех модулей и компонентов приложения. Это может затруднить разделение данных журнала по модулям или компонентам, что может быть важно при анализе данных журнала.', 'Риски безопасности: Корневой регистратор может быть изменен любым модулем приложения, что может создать риски для безопасности, если злоумышленник сможет изменить настройки журнала.', 'Вместо использования корневого логгера рекомендуется создавать логгер для каждого модуля или компонента приложения. Это позволяет независимо управлять настройками журнала для каждого из них, а также упрощает разделение данных журнала для анализа.', 'Для создания логгера для каждого модуля в Python можно использовать метод logging.getLogger(), который возвращает объект логгера, который можно использовать для регистрации сообщений для данного модуля. Ниже приведен пример создания логгера для модуля с именем my_module:', 'Метод getLogger() принимает аргумент name, который используется для идентификации логгера. Обычно в качестве имени логгера используется имя модуля, чтобы было легко определить, какой модуль генерирует сообщения.', 'Можно также записать его следующим образом:', 'После создания логгера для модуля можно использовать стандартные методы логирования сообщений, такие как debug(), info(), warning(), error() и critical().', 'По умолчанию логгеры передают сообщения до корневого логгера, поэтому важно установить атрибут propagate в значение False для каждого создаваемого логгера. Это предотвратит дублирование сообщений журнала или их обработку неожиданными регистраторами. Ниже приведен пример отключения распространения для регистратора:', 'Создавая отдельный логгер для каждого модуля приложения, вы можете независимо управлять настройками журнала и организовывать данные журнала таким образом, чтобы облегчить анализ и устранение неполадок.', 'По мере роста и усложнения приложения управление конфигурациями логгирования также усложняется. Централизация конфигураций поможет обеспечить последовательную и эффективную работу с журналами по мере масштабирования приложения. Кроме того, это позволяет настраивать параметры логгирования в зависимости от среды развертывания. Например, в средах разработки или тестирования можно регистрировать больше информации, а в производственных средах - только важную информацию.', 'Таким образом, настройка логгирования должна производиться на уровне приложения, а не отдельных модулей. Это позволит обеспечить последовательную обработку всех сообщений журнала в приложении. Это позволяет улучшить читаемость и сопровождаемость кодовой базы, а также упростить поиск и устранение проблем.', 'Ниже приведены некоторые шаги по централизованной настройке протоколирования в Python:', 'Создайте отдельный модуль для настройки логирования: Создайте новый модуль Python, который будет содержать весь код конфигурации. Этот модуль должен импортировать модуль logging и содержать все необходимые конфигурации.', 'Определите настройки логирования: Определите необходимые параметры, такие как формат журнала, уровень журнала и место вывода журнала. При необходимости можно определить дополнительные обработчики и форматоры.', 'Импортируйте настройки логирования в приложение: Импортируйте модуль конфигурации логирования в основной код приложения. Это позволит использовать одинаковые настройки во всех модулях приложения.', 'Установите конфигурацию логирования: Установите конфигурацию логирования, вызвав метод logging.config.dictConfig() и передав в него словарь настроек. Этот метод сконфигурирует модуль logging с заданными настройками.', 'Приведём пример конфигурации централизованного логгирования для Python-проекта, использующего библиотеку python-json-logger для вывода структурированных журналов:', 'В приведенном выше примере мы определили словарь LOGGING, содержащий все параметры конфигурации для logging, такие как формат журнала, уровень журнала и место вывода журнала. В logging_config.py используется метод logging.config.dictConfig() для настройки модуля logging с указанными параметрами.', 'Чтобы использовать эту централизованную конфигурацию logging в своем Python-приложении, достаточно импортировать файл logging_config и вызвать в начале приложения:', '{"asctime": "2023-10-08 09:54:52,238", "levelname": "INFO", "message": "An info", "module": "main"} {"asctime": "2023-10-08 09:54:52,238", "levelname": "WARNING", "message": "A warning", "module": "main"}', 'Уровни логгирования используются для обозначения степени серьезности сообщения журнала. Они представляют собой способ классификации сообщений журнала по степени важности или значимости. В Python каждый уровень журнала связан с числовым значением или именем константы, которая представляет собой определенный уровень серьезности.', 'Модуль logging поддерживает пять различных уровней, от самого высокого до самого низкого:', 'CRITICAL: На этом уровне отображаются ошибки, которые являются очень серьезными и требуют срочного решения, иначе само приложение может оказаться неспособным продолжать работу.', 'Например, если при подключении к базе данных произошла ошибка, мы можем перехватить исключение и зарегистрировать ошибку, используя критический уровень журнала, чтобы исследовать проблему и устранить ее до того, как приложение аварийно завершит работу или приведет к потере данных:', 'ERROR: Этот уровень показывает ошибку или невозможность выполнения некоторой задачи или функций. Например, вы можете использовать регистрацию ошибок для отслеживания ошибок базы данных или сбоев HTTP-запросов. Вот пример:', 'WARNING: На этом уровне отображается информация, указывающая на то, что произошло нечто непредвиденное или существует вероятность возникновения проблем в будущем, например, "мало места на диске". Это не ошибка, и приложение по-прежнему работает нормально, но требует вашего внимания.', 'INFO: На этом уровне отображается общая информация о приложении, позволяющая убедиться в том, что оно работает в соответствии с ожиданиями.', 'Например, вы можете использовать уровень INFO для отслеживания частоты использования определенных функций или заметных событий в жизненном цикле вашего приложения. Вот пример:', 'DEBUG: На этом уровне отображается подробная информация, обычно представляющая интерес только при диагностике проблем в приложении. Например, вы можете использовать уровень debug для регистрации данных, которые обрабатываются в функции:', 'Установка соответствующего уровня журнала также позволяет контролировать, какие сообщения будут отображаться в\xa0журнале. Например, если для\xa0уровня журнала установлено значение INFO, то в\xa0журнал будут записываться только сообщения с\xa0уровнем INFO и выше (т.\xa0е. WARNING, ERROR и CRITICAL). Это может\xa0быть полезно в\xa0производственных средах, где необходимо просматривать только те сообщения, которые указывают на\xa0проблему, требующую немедленного решения.', 'Вот пример того, как\xa0можно настроить уровень регистрации на\xa0ERROR в\xa0Python:', 'Ведение журнала может повлиять на\xa0производительность приложения, поэтому важно следить за\xa0тем, как\xa0часто и в\xa0каком объеме ведется журнал. Записывайте в\xa0журнал достаточно информации для\xa0диагностики проблем, но\xa0не\xa0настолько много, чтобы это влияло на\xa0производительность приложения.', 'Составление содержательных сообщений журнала важно, поскольку они помогают понять, что происходит в приложении в тот или иной момент времени и значительно упростить и ускорить этот процесс.', 'Более того, в производственных средах журналы часто контролируются для обеспечения бесперебойной работы приложения. Осмысленные сообщения журнала могут помочь операторам быстро выявлять возникающие проблемы.', 'Кроме того, по мере роста и развития приложений бывает трудно вспомнить, как работают различные части системы. Содержательные сообщения журнала могут служить формой документации, напоминая о том, что происходило в прошлом и как приложение развивалось с течением времени.', 'Для того чтобы сообщения журнала были содержательными, понятными, содержали контекст и помогали быстро диагностировать и устранять проблемы, приведем несколько советов:', 'Будьте ясны и лаконичны: Сообщения журнала должны быть простыми и понятными. Избегайте использования технического жаргона и сложных предложений.', 'Указывайте контекст: Включите информацию о контексте сообщения журнала. Это может быть функция или модуль, в котором было сгенерировано сообщение, пользователь, инициировавший это действие, входные параметры или любые другие данные, которые помогут понять сообщение.', 'Будьте последовательны: Используйте единый формат сообщений журнала во всех приложениях. Это облегчает их чтение и понимание, особенно при большом количестве сообщений журнала, как, например, в производственной среде.', 'Используйте подстановку значений: Для значений, которые будут динамически вставляться в сообщение журнала, используйте подстановку значений. Это облегчает чтение и понимание сообщения, а также предотвращает запись в журнал конфиденциальных данных. ', '{"asctime": "2023-04-27 20:31:54,737", "levelname": "INFO", "message": "Employee name: Alice, age: 30, salary: 50000"}', 'Предоставление полезной информации: Включите в журнал информацию, которая может быть использована для решения проблемы, например, предложения по ее устранению или ссылки на соответствующую документацию. Например:', 'Давайте, для понимания, рассмотрим некоторые примеры осмысленных и не очень осмысленных сообщений журнала:', 'Хорошие примеры сообщений:', "Пользователь с\xa0идентификатором 'user-123' успешно прошел аутентификацию", 'Файл успешно загружен на\xa0сервер по\xa0пути: /home/user/uploads/file.txt', 'Платеж в\xa0размере $50\xa0успешно обработан с\xa0идентификатором транзакции: 123\xa0456', 'В\xa0приведенных примерах сообщения журнала понятны, лаконичны и содержат полезную информацию для\xa0отладки и поиска неисправностей. В\xa0них указывается, какое действие\xa0было предпринято, успешно или\xa0нет, а\xa0также все необходимые подробности, которые могут помочь в\xa0выявлении причины проблемы.', 'Плохие примеры сообщений:', 'Произошла ошибка', 'Что-то пошло не так', 'Никогда такого не было и вот опять', 'А эти сообщения не информативные и не содержат полезной информаци.', 'В Python существует два основных способа форматирования строк: с помощью форматирования % и с помощью f-строк. Однако между этими двумя способами есть некоторые различия, которые в определенных случаях могут сделать один из них более подходящим, чем другой.', 'Ниже приведены некоторые соображения о том, когда следует использовать каждый из этих методов:', 'Необходима совместимость со старыми версиями Python, которые не поддерживают f-строки.', 'Необходимо форматировать более широкий диапазон типов данных, например, в устаревшем коде, который может использовать форматирование % для форматирования сложных типов данных.', 'Необходимо более точно управлять выводом.', 'Форматирование % может быть более производительным, чем f-строки, особенно при работе с большим количеством сообщений журнала.', 'Вы используете Python 3.6 или более позднюю версию и предпочитаете синтаксис и читабельность f-строк.', 'Вам необходимо включать выражения или вызывать функции в формат строки, например, когда вы хотите включить результат вычисления или вызова функции в сообщение журнала.', 'Необходимо упростить синтаксис форматирования строк и уменьшить вероятность синтаксических ошибок.', 'Недостатки производительности f-строк не являются существенными для вашего случая использования.', 'В конечном итоге выбор между %-форматированием и f-строками для форматирования строк в журналах зависит от ваших личных предпочтений, требований вашего приложения и используемой версии Python. Тем не менее, для улучшения читаемости и удобства сопровождения обычно рекомендуется последовательно использовать один из вариантов форматирования.', 'Традиционные текстовые форматы логирования, несмотря на свою полезность, могут быть сложны для чтения и анализа, особенно по мере усложнения приложений. Структурированное логгирование позволяет решить эту проблему за счет использования стандартизованного формата, например JSON.', 'Вот некоторые преимущества использования структурированного JSON-логирования:', 'Улучшенная читаемость и удобство поиска: Структурированные JSON-журналы легче читать и искать по сравнению с традиционными текстовыми форматами. Использование стандартизированного формата JSON позволяет легко анализировать данные журналов с помощью таких инструментов, как Elasticsearch или Kibana.', 'Согласованность между компонентами: Когда различные компоненты приложения используют разные форматы журналов, анализ журналов во всем стеке приложений может быть затруднен. Использование стандартизированного формата JSON гарантирует, что все компоненты будут использовать один и тот же формат, что упрощает анализ журналов во всем приложении.', 'Лучший контекст и метаданные: Структурированный JSON-журнал позволяет добавлять в него дополнительные метаданные, такие как идентификаторы запросов, пользователей или временные метки. Эти метаданные могут обеспечить ценный контекст при устранении неполадок и анализе журнальных данных.', 'Поддержка структурированных данных: JSON - это гибкий формат, поддерживающий структурированные данные, что позволяет легко регистрировать сложные структуры данных, такие как словари или списки. Использование структурированного формата позволяет избежать необходимости разбора текстовых журналов, который может быть сопряжен с ошибками и отнимает много времени.', 'Масштабируемость: По мере роста приложения объем генерируемых им журналов может значительно увеличиваться. Использование структурированного формата JSON позволяет легко масштабировать инфраструктуру протоколирования для работы с большими объемами журнальных данных.', 'Существует несколько библиотек логгирования на языке Python, поддерживающих структурированный JSON-логи, например python-json-logger, loguru и structlog.', 'Установив любую из этих библиотек и настроив логгер, можно использовать его для записи журналов в структурированном формате JSON. Для этого можно вызвать метод logger.info() (или любой другой метод логирования) и передать в него словарь пар ключ-значение, представляющих сообщение журнала.', 'Приведем пример с использованием loguru:', 'В результате в стандартный вывод будет записано сообщение журнала в формате JSON со следующей структурой:', '', 'Вы также можете использовать встроенные функции библиотеки протоколирования для добавления дополнительного контекста в журналы, например, временных меток, уровней журнала и трассировки стека исключений.', 'Ведение журнала без временной метки лишь немногим лучше, чем полное отсутствие информации о событии. Включение временных меток в журналы значительно облегчает жизнь тем, кто использует журналы для устранения неполадок. Кроме того, временные метки позволяют анализировать записи журнала для получения информации и аналитических данных о поведении пользователей и программ с течением времени.', 'Когда различные системы или компоненты должны обмениваться данными временных меток, важно, чтобы все они использовали один и тот же формат для обеспечения совместимости. Выбор неподходящего формата для временных меток может привести к хаосу и конфликту с другими сервисами, которые уже используются или могут быть использованы в будущем для управления журналами или мониторинга приложений.', 'Чтобы избежать этого, лучше всего принять стандартный формат временных меток. Одним из таких стандартов является стандарт ISO-8601, который представляет собой международно признанный стандарт обмена данными, связанными с датой и временем.', 'Придерживаясь этого стандарта, можно обеспечить совместимость временных меток с широким спектром инструментов и сервисов, что снижает вероятность возникновения конфликтов и проблем в будущем.', 'Вот как выглядит временная метка, выраженная в формате ISO-8601:', '2022-06-15T04:32:19.955Z ', 'Это базовый пример настройки форматирования для разрешения временных меток ISO-8601:', 'Конфиденциальная информация не должна попадать в журналы, поскольку журналы часто используются для поиска и устранения неисправностей и отладки и могут содержать конфиденциальную информацию, такую как пароли пользователей, номера кредитных карт и другие частные данные. Если журналы не защищены и не управляются должным образом, они могут стать мишенью для хакеров и других злоумышленников, которые попытаются получить доступ к этим конфиденциальным данным.', 'Кроме того, журналы часто хранятся в текстовых файлах или других незашифрованных форматах, что делает их уязвимыми для несанкционированного доступа или раскрытия. Не допуская попадания конфиденциальных данных в журналы, можно защитить частную жизнь пользователей и снизить риск утечки данных или других инцидентов безопасности.', 'Ниже приведены общие рекомендации по сохранению конфиденциальных данных в журналах и снижению риска их раскрытия:', 'Избегайте записи конфиденциальных данных в журнал: Самый простой способ не допускать попадания конфиденциальных данных в журналы - не регистрировать их вообще. Убедитесь, что система протоколирования настроена на исключение конфиденциальных данных.', 'Маскируйте или редактируйте конфиденциальные данные: Если конфиденциальные данные необходимо регистрировать, их можно замаскировать или отредактировать. Например, можно заменить номера кредитных карт или пароли серией звездочек или заменить их хэш-значением.', 'Например, если номер кредитной карты имеет вид "1234-5678-9012-3456", его можно замаскировать или отредактировать. Вот как использовать фильтры для реализации редактирования журнала в Python:', '{"asctime": "2023-04-27T21:36:39Z", "levelname": "INFO", "message": "User made a payment with credit card number: [REDACTED]"}', 'Используйте переменные окружения: Такие конфиденциальные данные, как ключи API или учетные данные баз данных, можно хранить в переменных окружения, а не вписывать их в код. Таким образом, значения не будут занесены в журнал.', 'Ограничение области действия журналов: Можно ограничить объем журналов, записывая в них только то, что необходимо. Это означает, что можно регистрировать только ошибки или критические события, а не все события. Кроме того, можно ограничить объем информации, регистрируемой приложением.', 'Шифрование данных журнала: Для обеспечения безопасности конфиденциальной информации можно зашифровать данные журнала. Это позволит обеспечить доступ к журналам и их чтение только авторизованным сотрудникам.', 'Используйте безопасное решение для управления журналами: Убедитесь, что используемая система ведения журналов безопасна и имеет соответствующие средства контроля для предотвращения несанкционированного доступа к конфиденциальным данным.', 'Ротация файлов журнала означает периодическое создание новых файлов журнала и архивирование или удаление старых. Цель ротации журналов - управление размером  файлов журналов, повышение производительности, сохранение данных журнала, упрощение отладки и повышение безопасности. Если ротация журналов не производится, они могут занимать много места на диске и вызывать проблемы с производительностью.', 'Существует несколько стратегий ротации файлов журнала, в том числе:', 'Ротация по времени: Создание нового файла журнала через фиксированные промежутки времени (например, ежедневно или еженедельно) и архивирование или удаление старых файлов журнала.', 'Ротация по размеру: Создание нового файла журнала при достижении текущим файлом журнала определенного размера (например, 10 МБ) и архивирование или удаление старых файлов журнала.', 'Гибридная ротация: Комбинирование стратегий ротации на основе времени и размера для создания новых файлов журнала через фиксированные промежутки времени и архивирования или удаления старых файлов журнала на основе ограничений по размеру.', 'В Python ротацию лог-файлов можно выполнять с помощью встроенного модуля logging. Модуль logging предоставляет класс RotatingFileHandler, который позволяет создавать файлы журнала, ротируемые в зависимости от заданного размера или временного интервала.', 'Приведем пример использования класса RotatingFileHandler для ротации лог-файлов по размеру:', 'В этом примере мы создаем регистратор с именем my_logger и устанавливаем уровень регистрации DEBUG. Затем мы создаем RotatingFileHandler с максимальным размером файла 1 МБ и количеством резервных копий 5.', 'Это означает, что как только размер файла журнала достигнет 1 МБ, будет создан новый файл журнала, а старый файл будет заархивирован. Счетчик резервных копий задает количество сохраняемых архивных файлов журнала.', 'Мы задаем формат обработчика, включающий временную метку, имя регистратора, уровень журнала и сообщение журнала. Наконец, мы добавляем обработчик в логгер и выводим отладочное сообщение.', 'Это лишь простой пример того, как ротировать лог-файлы с помощью модуля logging в Python. Обычно мы рекомендуем доверить ротацию журналов внешнему инструменту, например logrotate, который поможет обеспечить согласованность политик ротации журналов для нескольких приложений или служб, работающих на одной машине.', 'Как только ваше приложение будет развернуто в продакшене, оно сразу же начнет генерировать журналы, которые обычно хранятся на хост-сервере. Если для просмотра и анализа журналов достаточно одного-двух серверов, то при масштабировании приложения на десятки серверов такая практика становится утомительной и неэффективной.', 'Централизация журналов позволяет упростить управление журналами за счет объединения журналов из нескольких источников в одном месте. Это упрощает поиск, анализ и мониторинг журналов и снижает необходимость управления журналами в нескольких системах.', 'Централизация журналов в одном месте имеет ряд преимуществ, среди которых можно выделить следующие:', 'Улучшение процесса поиска и устранения неисправностей: Централизация журналов облегчает поиск и устранение неисправностей, поскольку обеспечивает единый источник истины для данных журналов. Это позволяет коррелировать события в различных системах и быстрее выявлять первопричину проблем.', 'Повышение уровня безопасности: Централизация журналов позволяет повысить уровень безопасности за счет централизованного мониторинга и обнаружения угроз безопасности. Анализируя журналы из нескольких систем, можно выявить закономерности и аномалии, которые могут свидетельствовать о нарушении безопасности.', 'Повышение масштабируемости: Централизация журналов позволяет повысить масштабируемость за счет централизованного сбора и хранения больших объемов журнальных данных. Это облегчает масштабирование инфраструктуры журналов по мере роста системы.', 'Содействие соблюдению нормативных требований: Централизация журналов может способствовать соблюдению нормативных требований, поскольку обеспечивает централизованное хранение и аудит журнальных данных. Это облегчает демонстрацию соответствия нормативным требованиям и стандартам.', 'При выборе облачного решения для ведения журналов необходимо учитывать несколько факторов:', 'Функции: Ищите решение, предоставляющее необходимые функции, такие как потоковая передача журналов в реальном времени, поиск и анализ, а также оповещения и уведомления.', 'Масштабируемость: Убедитесь, что решение способно работать с текущим объемом журналов и масштабироваться по мере его роста.', 'Интеграция: Убедитесь, что решение может интегрироваться с существующими системами и инструментами, такими как фреймворки протоколирования, средства мониторинга и оповещения, облачные платформы.', 'Безопасность: Ищите решение, обеспечивающее надежные средства защиты, такие как шифрование, контроль доступа и политики хранения данных.', 'Стоимость: Рассмотрите стоимость решения, включая авансовые платежи, текущие расходы на подписку и дополнительные расходы на такие функции, как хранение или обработка данных.', 'Поддержка: Проверьте уровень поддержки, предоставляемой поставщиком, включая документацию, техническую поддержку и форумы сообщества.', 'Простота использования: Ищите решение, которое легко устанавливать, настраивать и использовать, имеет интуитивно понятный интерфейс и четкую документацию.', 'Учитывая эти факторы, вы сможете выбрать облачное решение для ведения журналов, которое будет отвечать вашим потребностям и поможет вам лучше управлять и анализировать данные журналов. ', 'Здесь была реклама Logtail', 'В заключение следует отметить, что применение лучших практик ведения журналов в Python может значительно повысить удобство обслуживания, производительность и безопасность приложения. Следуя этим рекомендациям, можно обеспечить хорошую структуру журналов, их правильное форматирование и удобство поиска и анализа. Кроме того, можно снизить риск раскрытия конфиденциальных данных в журналах и минимизировать влияние размера файла журнала на производительность системы.', 'Для достижения наилучших результатов при ведении журналов важно использовать соответствующие уровни и форматы сообщений, а также реализовать правильную обработку ошибок и регистрацию исключений. Кроме того, следует рассмотреть возможность внедрения политик ротации и хранения журналов, чтобы обеспечить надлежащее управление и архивирование журналов.', 'Приоритет протоколирования как ключевого аспекта процесса разработки позволяет получить ценные сведения о поведении приложения, быстро диагностировать проблемы и, в конечном счете, повысить общее качество и надежность программного обеспечения.', 'Спасибо за прочтение, Happy Logging!', 'Logging Cookbook', 'Логирование в Python: руководство разработчика', 'loguru', '', '', 'Ищу работу', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}, {'header': 'Как работать с процессами и потоками в Python', 'text': ['Раскрывать тему параллельного или асинхронного программирования непросто. Во-первых, она перегружена терминологией и трудна для понимания. Как правило, тонкости и особенности работы с языками усваиваются, лишь когда столкнешься с ними на практике. Во-вторых, в контексте Python тоже много своих подводных камней. Но сегодня почти любой современный web-сервис сталкивается с необходимостью многопоточности или асинхронности. Поскольку это многопользовательская среда, мы хотим направить всю процессорную мощность не на ожидание, а на решение прикладных задач бизнеса, чтобы все пользователи вовремя получили необходимые данные.\xa0', 'Эта статья будет полезна тем разработчикам, которые хотят выполнять больше работы за одно и то же время, и задействовать все ресурсы своего железа. Проще говоря, делать больше, и при этом обходиться меньшими ресурсами. Пусть железо работает, а не простаивает.', 'Давайте возьмем за отправную точку ситуацию, когда у нас есть приложение, которое работает по стандартной схеме клиент – сервер:', 'Клиент посылает запрос и получает ответ. А теперь представьте, что в нашем приложении есть кнопка, которая формирует большой отчет. Когда пользователь нажимает на нее, программа долго обрабатывает запрос. Клиент ждет ответа, и пока отчет не будет сформирован, он не сможет пользоваться интерфейсом приложения.', 'Как мы можем помочь пользователю продолжить взаимодействие с нашим приложением, пока формируется отчет? Мы можем создать отдельный процесс, отдельный поток, и выполнять код асинхронно.', 'Рассмотрим каждое понятие отдельно.', 'Процессы являются контейнерами. Их основная задача – изолировать программы друг от друга, чтобы одна не могла получить доступ к памяти другой.', 'В контексте Python каждому процессу выделен свой интерпретатор. Когда мы запускаем несколько процессов из кода, то мы обнаруживаем такое же количество процессов в мониторинге системы.', 'Небольшой пример создания процессов:', 'Процессы представлены как экземпляр класса Process из встроенной библиотеки multiprocessing.', 'У нас есть функция, которая принимает 1 параметр и печатает приветствие с переданным параметром. Внутри конструкции if мы создаем два процесса p1 и p2 в качестве параметров, то есть мы передаем:', 'target – с названием выполняемой функции,', 'args – параметры для функции, которую мы будем вызывать,', 'daemon – с флагом True, который говорит нам, что процесс будет являться «демоном» – об этом чуть позже.', 'Для того чтобы процесс стартовал, мы вызываем у каждого метод .start().', 'Но ниже мы вызываем еще и метод .join().', 'У нас есть основной (главный) процесс, который содержит весь код нашей программы, и два дополнительных (фоновых) p1, p2. Их мы создаем, когда мы прописываем параметр daemon=True. Так мы как раз и указываем, что эти два процесса будут второстепенными. Если мы не вызовем метод join у фонового процесса, то наша программа завершит свое выполнение, не дожидаясь выполнения p1 и p2.', 'Процессы не могут работать параллельно на одноядерной машине.\xa0', 'Параллельное вычисление – выполнение двух и более задач одновременно, когда каждое ядро процессора берет задачу и выполняет ее. На многоядерной машине параллельное вычисление – нормальная практика. Однако количество ядер у нас ограничено, причем весьма сильно, а процессов в системе работает много.', 'Познакомимся с еще одним термином — вытесняющая многозадачность.', 'Вытесняющая многозадачность — это такой способ управления задачами, при котором решение о переключении процессора с выполнения одного процесса на выполнение другого принимается планировщиком операционной системы.', 'Предположим, что у нас одноядерный процессор и ему приходится выполнять работу множества программ одновременно. Как он это делает?', 'В этом случае каждой программе выделяется небольшой промежуток времени, то есть программы конкурируют за доступ к ядру. Процессор сам переключает контекст выполнения, и таким образом создается впечатление, что программы работают одновременно. Но это не совсем так.', 'Проще говоря, одна программа поработала какое-то время, и процессор переключает контекст на другую, чтобы она выполнила запланированные действия, передала обратно и так далее.', 'Когда количество процессов превышает количество ядер, на помощь приходит конкурентное вычисление.', 'Первое, о чем хотим сказать про потоки — интерфейсы работы с процессами и потоками в Python очень похожи.', 'Потоки живут внутри процессов, потребляют меньше ресурсов и разделяют общую память внутри процесса. Во многих языках программирования потоки создавались именно для того, чтобы выполнять задачи параллельно, но не в Python. А виноват в этом GIL.', 'GIL (Global interpreter lock) следит за тем, чтобы в один момент времени работал лишь один поток. Механизм похож на то, как процессы конкурируют за ядро. Но в отличие от процессов GIL освобождается при вызове блокирующей функции операций ввода/вывода. Другой механизм его освобождения – time.sleep(). Об этом позже.', 'Как видно, процесс создания потоков идентичен алгоритму формирования процессов.', 'Теперь, когда мы познакомились с основными понятиями, продемонстрируем несколько проблем, которые встречаются в многопоточном программировании.', 'Первая проблема – Race Condition или состояние гонки.', 'На изображении мы видим два запуска одной и той же программы, в которой есть два потока: в первом функция увеличивает переданное число на единицу, а во втором — мы умножаем число на 2.', 'Слева вы видите первый запуск программы. Первый поток берет значение из глобальной переменной x, прибавляет 1 и записывает в x результат = 3. Затем второй поток начинает работу. Он берет из переменной x значение 3, умножает на 2 и записывает результат = 6.', 'На правой схеме – второй запуск программы, где сперва в работу вступает поток 2, он выполняет те же операции, берет x = 2, умножает на 2 и фиксирует результат 4. Затем вступает\xa0 поток 1, читает 4 из x, увеличивает на единицу и записывает 5.', 'Так как оба потока меняли порядок работы программы, но выполняли ее по очереди, у нас не возникало никакого конфликта, и мы получали ожидаемый результат.', 'Но давайте посмотрим на такой поток выполнения:', 'Поток 1 вступает в работу, читает переменную x и переключает контекст на поток 2 (context switch). Затем поток 2 берет значение из x = 2, умножает на 2 и записывает в x = 4. Процессор переключает контекст на поток 1, а в потоке 1, как мы помним, сохранено значение x = 2. В итоге он увеличивает значение на единицу и записывает в x = 3, а значит, на выходе мы получаем 3.', 'Один поток обогнал другой при переключении контекста, и мы получили непредсказуемый результат. Такое событие называется Race condition. Как тогда быть уверенным в том, что поток, взявший в работу какие-то данные, выполнит свою работу, перед тем как переключит свой контекст на другой потоку?', 'Вот пример:', 'Посмотрим на результат:', 'Вместо 30 получаем 20.', 'На помощь нам может прийти такое понятие как Lock.', 'Lock (замок) – объект, который захватывает поток, и пока поток не освободит (release) Lock, другие потоки не смогут ничего сделать с этими данными, захваченными при помощи замка.', 'Вот теперь как и должно быть:', 'Несмотря на то, что Lock помогает решить проблему с Race condition, он может привести к другой сложной ситуации, когда один поток ждет освобождение одного замка, а другой ждет освобождение от первого. Такое ожидание приводит к ситуации взаимного тупика, известного как Deadlock.', 'И теперь посмотрим результат:', 'Наша программа зависает в ожидании разблокировки, которая никогда не произойдет. Так же Deadlock произойдет при попытке заблокировать наш Lock повторно в том же потоке.', 'Решить проблему с Deadlock могут помочь различные механизмы синхронизации потоков. Разберем один из таких примеров – Semaphore (Семафор).', 'Semaphore прост в понимании, если его представить в виде объекта, который ограничивает выполнение блока кода установленным количеством, по умолчанию это 1. При каждом вхождении в блок кода Semaphore счетчик уменьшается. Если счетчик дошел до 0, все потоки блокируются, и пока поток не освободит семафор, другие будут ждать разрешения подключиться.', 'Посмотрим Semaphore на примере реализации очереди из реального кейса.', 'В результате увидим, что функция выполнялась группами по 3 потока. То есть одновременно не может выполняться кусок кода с блокировкой через Semaphore больше, чем указан в инициализации класса Semaphore. Видим паузы в 2 секунды между блокировками.', 'Это удобно использовать, например, в таком виде: если база данных может держать не более 30 соединений, то инстанциируем Semaphore со значением 30. Блокируем, когда поднимаем соединение и разблокируем, когда освобождаем.', 'Есть несколько способов синхронизации потоков, которые подходят для тех или иных ситуации. Примеры можно посмотреть в документации.', 'Теперь поговорим об освобождении GIL.', 'CPython управляет памятью с помощью подсчета ссылок. То есть для каждого объекта Python подсчитывается, сколько на него указывается ссылок с других объектов, использующих его в данный момент. При добавлении ссылки счетчик увеличивается, при удалении ссылки счетчик уменьшается. А когда счетчик ссылок становится 0 — это означает, что объект больше не нужен, и его можно удалить из памяти.', 'Следовательно, если не будет GIL, который запрещает Python процессу выполнять более одной команды байт-кода в каждый момент времени, то при подсчете ссылок может случиться Race-condition, с подсчетом ссылок на объекты, как это было в примере с переменными выше.', 'Итак, раз GIL запрещает одновременное выполнение Python кода, из этого следует, что он высвобождается, когда Python код не выполняется. Когда мы ждем, например, пока считается файл с диска или придет ответ на запрос к сайту. Так как в этом случае низкоуровневые системные вызовы работают за пределами Python кода и среды выполнения, и код операционной системы не взаимодействует напрямую с объектами Python, соответственно, они не увеличивают и не уменьшают счетчик ссылок. GIL захватывается снова, когда данные переносятся в объект Python.', 'Стало быть, если мы сделаем библиотеку, даже с CPU-bound нагрузкой, где мы не взаимодействуем с объектами Python (словарями, списками, целыми числами и т. д.) или большая часть библиотеки не взаимодействует, то мы можем освободить GIL. Например, библиотеки hashlib и NumPy выполняют расчеты на чистом C и освобождают GIL.', 'time.sleep() — реализация этой функции освобождает GIL и выполняется на уровне системы и работает вне кода Python.', 'Как видите, в многопоточности существует огромное количество нюансов и проблем. В реальных больших программах будет непросто понять, где происходит ошибка. Рассмотрим, как можно распараллелить выполнение программ. В этом поможет асинхронность.', 'Для того чтобы лучше понять асинхронность, окунемся в далекий 1992 год. Тогда была выпущена операционная система Windows 3.1 которая использовала кооперативную многозадачность.', 'Кооперативная многозадачность — это тип многозадачности, при котором фоновые задачи выполняются только во время простоя основного процесса и только в том случае, если на это получено разрешение основного процесса.', 'То есть время, когда исполняемая программа управляет передачей управления другому процессу и передачей процессорного времени.', 'Недостатком такого исполнения является то, что если одна задача зависла. Зависает вся система.\xa0', 'А вот преимущества такого решения: разработчик программы отдает управление тогда, когда он посчитает это нужным.', 'Теперь мы подобрались к понятию асинхронного программирования.', 'Асинхронное программирование — выполнение программы в неблокирующем режиме системного вызова, что позволяет потоку программы продолжить работу.', 'Благодаря асинхронному программированию в одном процессе и даже потоке мы можем выполнять сразу множество задач. Как же это происходит?', 'В реальном программировании, а особенно в web-разработке мы очень часто чего-то ждём и не делаем полезной работы. Вот несколько примеров:', 'Отправили запрос на сторонний ресурс и ждем ответа.', 'Отправили запрос в базу данных и ждем результата запроса.', 'Читаем или записываем файл на диск.', 'И так далее.', 'Получается что мы ждем, ждем и ждем. А в это время наша программа могла бы выполнить множество полезной нагрузки. И мы как разработчики ПО точно знаем, где мы будем ожидать. Ничего не напоминает? Да! Похоже на кооперативную многозадачность, но только не на уровне операционной системы, а на уровне процесса.', 'На рисунке видно, что периодов ожидания много. А что будет если во время ожидания мы будем выполнять полезную работу?', 'Как видно на рисунке, в моменты ожидания мы выполняем уже две задачи за то же самое время. Чем быстрее мы выполняем работу и чем дольше мы ожидаем, тем больше задач мы можем сделать за одно и то же время.', 'Для реализации такого поведения асинхронности есть несколько подходов:', 'Реализация на основе коллбэков.', 'Реализация на основе корутин.', 'Оба подхода имеют место. Например, мощный фреймворк TORNADO реализован именно на основе коллбэков.\xa0', 'У этого подхода есть ряд недостатков:', 'Код перестает выглядеть как синхронный, что усложняет отладку.', 'Ад коллбэков, в котором будет сложно разобраться. Просто погуглите фразу “callback hell”.', 'Если после этих минусов желание попробовать ещё осталось, то можно в подходе легко разобраться.', 'А вот подход на основе корутин мы разберем более глубоко. У него также есть ряд преимуществ и недостатков:', 'Плюсы:', 'Асинхронный код выглядит как синхронный.', 'Нет проблем с общей памятью, и избавляемся от синхронизаций.', 'Не нужно переключать контекст между задачами, что экономит ресурсы нашего компьютера.', 'Теперь нам не нужны коллбэки, но их также можно использовать.', 'Минусы:', 'Чуть более сложный подход для понимания.', 'В Python есть ряд библиотек, которые позволяют работать с асинхронностью:', 'asyncio — основная библиотека для работы с асинхронным программированием,', 'aiohttp — для асинхронной работы с запросами,', 'aiofiles — для работы с файловой системой.', 'Как вы наверное заметили, у библиотек есть префикс aio (asynchronous input output, асинхронный ввод-вывод). Тут как раз решается проблема ожидания. Такие задачи называют IO bound.', 'Рассмотрим термины, которые нам помогут во всём разобраться.', 'Event loop (цикл событий) — ядро каждого приложения asyncio. Циклы событий запускают асинхронные задачи и обратные вызовы, выполняют операции сетевого ввода-вывода и запускают подпроцессы. Официальную документацию можно прочесть тут.', 'Корутины — это специальные функции, которые запускаются, используя цикл событий. У них есть особенность — они говорят, когда они будут ждать и передают управление обратно, чтобы другая задача могла выполняться во время ожидания.', 'Футуры — это определение обычно воспринимается тяжелее всего, но я постараюсь объяснить как можно проще. Это объект, в котором хранится результат и состояние задачи:\xa0', '+ ожидание (pending)\xa0', '+ выполнение (running)\xa0', '+ выполнено (done)\xa0', '+ отменено (cancelled)', 'То есть в процессе работы мы можем управлять задачами в зависимости от футуры (статус/результат) задачи.', 'Корутины могут быть реализованы с использованием генераторов или async/await. Мы выбираем второй вариант как более лаконичный.', 'Посмотрим, как это выглядит в коде.\xa0', 'Создадим первую корутину:', 'Теперь у нас есть асинхронная функция. Научимся теперь её запускать. Первое, что хочется сделать — вызвать её как обычную функцию. Давайте попробуем:', 'При выполнении ничего не произошло. А вот наш друг интерпретатор выдал предупреждение.', 'Тут из сообщения становится понятно, что при вызове таким образом асинхронной функции она превращается в асинхронную корутину.', 'Как же можно запустить корутину?', 'Из другой корутины.', 'Обернуть в задачу.', 'Запустить через метод asyncio.run и\xa0 run_until_complete из цикла событий.', 'И получили результат, который ожидали.', 'Вызов метода asyncio.run(hello()) принимает корутину, которую необходимо выполнить, открывает цикл событий, выполняет корутину и закрывает цикл событий.', 'Что делать, если необходимо запустить две задачи конкурентно?', 'Это поможет нам сделать asyncio.gather, но раз функция asyncio.run принимает только одну корутину, создадим новую корутину, которая будет запускать конкурентно несколько задач.', 'И получаем тот результат, который ожидали.', 'Время выполнения около 5 секунд. Если бы две функции выполнялись синхронно, то время выполнения составило около 10 секунд.', 'А если нам необходимо выполнить 10 тысяч раз, сколько времени это займёт? Видоизменяем код:', 'Получаем результат. Посмотрим на вывод последних нескольких строк, которые нам говорят, сколько минут выполнялся код.', 'Неплохо. Чуть больше тех же самых 5 секунд.\xa0', 'Что же это значит? Представьте, что запрос на сторонний сайт занимает порядка 5 секунд. И нам необходимо получить результат тех же самых 10000 запросов. Используя асинхронное программирование, 10 тысяч запросов сеть будут выполняться чуть больше 5 секунд. Правда, здорово?', 'Но мы пойдем дальше и будем уже более гибко и детально работать с асинхронным выполнением:', 'В этом примере мы более гибко управляем циклом событий. Сначала получаем/создаем основной цикл событий. Затем создаем задачи и объединяем их запускаем на выполнение, пока не завершится. Затем уже закрываем цикл событий. Нужно помнить, что порядок выполнения задач при конкурентном выполнении мы не можем гарантировать, и необходимо разрабатывать приложения с учетом этой особенности.', 'Теперь давайте попробуем управлять выполнениями задач и рассмотрим код ниже:', 'Результат будет таким:', 'Теперь только представьте, какие возможности у нас открылись! Например, мы можем запрашивать курсы валют сразу с нескольких ресурсов, и принимать результат того, который быстрее ответит. Чувствуете, как растет скорость и устойчивость приложения?', 'Или ещё такой пример. Мы можем динамически добавлять новые задачи, когда одна из задач выполнена. Например, парсить сайт в 20 задач. Только в этом случае добавляем к футурам в статусе pending новую задачу.', 'А самое приятное — наши асинхронные задачи выглядят как синхронные:', 'Работая в один поток, можно делать больше работы;', 'Удобная отладка;', 'Нет проблем с блокировками;', 'Можем использовать обратные вызовы (коллбэки) и отложенные обратные вызовы вдобавок к нашему асинхронному коду. Для этого посмотрите на методы цикла событий call_soon, call_later, call_at.', 'Для работы с конкурентностью есть различные библиотеки, которые решают самые востребованные задачи IO:', 'aiohttp — работа с HTTP запросами;', 'aiofiles — работа с файлами.', 'Мы рассмотрели темы асинхронного и параллельного программирования. Теперь осталось дело за малым, опробовать всё это на практике.\xa0', 'Плюсы:', '+ Работают параллельно.', '+ Используют все ресурсы ядра процессора.', '+ Можно загрузить все ядра процессора.', '+ Изолированная память.', '+ Независимые системные процессы.', '+ Подходит для CPU bound операций.', 'Минусы:', 'Если необходимо использовать общую память, то необходимо синхронизировать, так как нет общих переменных.', 'Требуют больших ресурсов, так как запускают отдельный интерпретатор.', 'Используем там, где обрабатываемые данные не зависят от других процессов и данных. Например:', '\t+ Расчет нейронных сетей.', '\t+ Обработка изолированных фотографий.', '\t+ Архивирование изолированных файлов.', '\t+ Конвертация форматов файлов.', 'Плюсы:', '+ Работают параллельно.', '+ Используют немного памяти.', '+ Общая память.', 'Минусы:', 'Одновременный доступ к памяти может приводить к конфликтам.', 'Сложный код.', 'Используем там, где код много раз ожидает, пока выполнится задача. Например:', '+ Работа с сетью.', 'Плюсы:', '+ Работает в одном процессе и в одном потоке.', '+ Экономное использование памяти.', '+ Подходит для I/O bound операций.', '+ Работает конкурентно.', 'Минусы:', 'Сложность отладки.', 'CPU bound операции блокируют все задачи.', 'Используем там, где код много раз ожидает. Например:', '+ Работа с сетью.', '+ Работа с файловой системой.', 'Основываясь на конкретных плюсах и минусах, нам становится легче выбирать подход и грамотно использовать процессорное время и память. Хотя Python является мультипарадигменным языком общего назначения, на нем можно писать практически любые программы, используя любой подход. Но особенно приятно, когда ваш веб-сервис может держать в сотню раз больше соединений или отрабатывать запросы в 8 раз быстрее, обходясь меньшим количеством памяти.', 'Спасибо за внимание! Надеемся, что этот материал был полезен для вас.\xa0', 'Авторские материалы для разработчиков мы также публикуем в наших соцсетях –\xa0ВК\xa0и\xa0Telegram.', '', 'Пользователь', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}, {'header': 'Построение пайплайна обработки данных в реальном времени с использованием Python', 'text': ['Привет, Хабр!', 'Обработка данных в реальном времени стала важной составной частью современного  мира. Бизнес, исследователи, разработчики и многие другие специалисты сталкиваются с необходимостью обрабатывать потоки данных в реальном времени, чтобы принимать решения быстрее и более точно.', 'Обработка данных в реальном времени позволяет:', 'Мониторить и реагировать на события в режиме реального времени, что особенно важно в сферах безопасности, финансов и здравоохранения.', 'Улучшать качество обслуживания клиентов, предоставляя персонализированные рекомендации и ответы на запросы моментально.', 'Оптимизировать производственные процессы и управлять ресурсами на основе актуальных данных.', 'Предсказывать будущие события и тренды, что помогает в принятии стратегических решений.', 'В этой статье мы рассмотрим как построить пайплайн обработки данных в реальном времени с использованием Python. ', 'Для обработки данных в Python существует множество библиотек, каждая из которых предназначена для определенных задач. Ниже представлены некоторые ключевые библиотеки:', 'NumPy: NumPy предоставляет мощные средства для работы с многомерными массивами данных и выполнения математических операций над ними. Это основа многих других библиотек для обработки данных.', 'Pandas: Pandas предоставляет высокоуровневые структуры данных, такие как DataFrame и Series, и множество функций для работы с табличными данными. Это отличное средство для анализа и манипуляции данными.', 'Matplotlib и Seaborn: Эти библиотеки предоставляют возможности для визуализации данных. Matplotlib является более базовой библиотекой, в то время как Seaborn упрощает создание красочных графиков и диаграмм.', 'Scikit-Learn: Если вам нужно выполнять машинное обучение, Scikit-Learn предоставляет широкий спектр алгоритмов для классификации, регрессии, кластеризации и многих других задач.', 'Kafka-Python: Для работы с Apache Kafka, существует библиотека Kafka-Python, которая обеспечивает интеграцию с Kafka для потоковой обработки данных.', 'Источники данных играют фундаментальную роль в построении реального времени пайплайна обработки данных. Это места, откуда ваша система будет получать информацию для дальнейшей обработки. Два основных типа источников данных:', 'Сенсоры и устройства сбора данных', 'Сенсоры и устройства сбора данных являются одними из наиболее распространенных источников данных в области обработки данных в реальном времени. Эти устройства способны собирать данные с различных физических и окружающих параметров. Примерами могут служить датчики температуры, влажности, давления, GPS-устройства, мобильные устройства и многие другие.', 'Для взаимодействия с сенсорами и устройствами сбора данных в Python, вы можете использовать библиотеки и инструменты, такие как PySerial для работы с последовательным портом, Adafruit CircuitPython для работы с датчиками, и другие. Важно учитывать, что обработка данных с сенсоров требует обработки и фильтрации данных в реальном времени, чтобы извлечь полезную информацию.', 'Пример кода для чтения данных с датчика температуры DS18B20:', 'Внешние источники данных (API, базы данных и т. д.)', 'Внешние источники данных предоставляют данные через интерфейсы, такие как API или доступ к базам данных. Эти источники могут включать данные из внешних веб-сервисов, баз данных, журналов событий и многих других источников.', 'Для работы с внешними источниками данных в Python вы можете использовать библиотеки, такие как requests для HTTP-запросов к API или SQLAlchemy для взаимодействия с различными базами данных.', 'Пример кода для запроса данных из API с использованием библиотеки requests:', 'Правильный выбор и настройка источников данных критически важны для успешного создания пайплайна обработки данных в реальном времени.', 'Построение потока данных - это ключевой этап создания реального времени пайплайна обработки данных. Это процесс, который позволяет получать, передавать и обрабатывать данные в реальном времени. ', 'Использование Apache Kafka для создания потоков данных', 'Apache Kafka предоставляет надежный и масштабируемый способ передачи данных между различными компонентами вашего пайплайна обработки данных в реальном времени. Kafka особенно полезен при работе с большим объемом данных и требованиями к низкой задержке.', 'Важными компонентами Kafka являются:', 'Producer (Производитель): Этот компонент отвечает за отправку данных в темы (topics) Kafka. Производительы берут данные из источников и публикуют их в темы, которые могут быть прочитаны другими компонентами.', 'Broker (Брокер): Брокеры Kafka - это серверы, на которых хранятся и обрабатываются данные. Они принимают данные от производителей, хранят их в темах и предоставляют доступ к данным потребителям.', 'Consumer (Потребитель): Потребители получают данные из тем Kafka и обрабатывают их. Это могут быть приложения, которые выполняют различные операции на данных.', 'Topic (Тема): Темы представляют собой категории данных в Kafka. Данные публикуются в темы и могут быть прочитаны несколькими потребителями. Темы обеспечивают многократное чтение данных и масштабируемость.', 'Пример создания темы и отправки сообщения с использованием библиотеки Kafka-Python:', 'Роли и задачи Kafka-кластера', 'Kafka работает как распределенный кластер, и в нем существуют разные роли и задачи:', 'ZooKeeper: Kafka использует Apache ZooKeeper для управления состоянием кластера и обеспечения отказоустойчивости. ZooKeeper следит за состоянием брокеров Kafka, регистрирует новые брокеры и управляет выбором лидера для каждой темы.', 'Лидер и реплики: Каждая тема Kafka имеет одного лидера и несколько реплик. Лидер отвечает за запись данных в тему, а реплики хранят копии данных для обеспечения отказоустойчивости. Если лидер выходит из строя, одна из реплик становится новым лидером автоматически.', 'Разделение тем: Kafka разделяет данные на разделы (partitions), и каждый раздел обрабатывается отдельным потребителем. Это обеспечивает параллельную обработку данных и масштабируемость.', 'Потребители и группы потребителей: Потребители читают данные из тем Kafka. Они объединяются в группы потребителей, что позволяет обрабатывать данные параллельно. Каждая группа потребителей читает данные из своих разделов.', '', 'Создание и управление Kafka-кластером требует определенных навыков и знаний о конфигурации, мониторинге и настройке. Однако, правильно настроенный Kafka-кластер может обеспечить надежную и масштабируемую инфраструктуру для вашего реального времени пайплайна обработки данных.', 'Не забывайте также мониторить состояние кластера, настраивать репликацию данных для отказоустойчивости и управлять группами потребителей для эффективной обработки данных в режиме реального времени.', 'Обработка данных в потоке является ключевой частью реального времени пайплайна обработки данных.', 'Потоковая обработка данных с использованием Apache Spark Streaming', 'Apache Spark Streaming - это компонент Apache Spark, который позволяет обрабатывать потоки данных в режиме реального времени. Он предоставляет абстракцию под названием "DStream" (Discretized Stream), которая представляет собой последовательность данных, поступающих в потоке.', 'Для создания потока данных с использованием Apache Spark Streaming, вам потребуется настроить и запустить кластер Apache Spark и затем настроить DStream для чтения данных из Kafka, файловой системы, сокета или других источников.', 'Пример создания простого потока данных с использованием Apache Spark Streaming и чтения данных из сокета:', 'Этот пример создает поток данных, который слушает сокет на порту 9999, разделяет строки на слова, считает количество каждого слова и выводит результаты в реальном времени.', 'Разработка пользовательских функций обработки', 'Для обработки данных в потоке вы часто должны разрабатывать пользовательские функции обработки. Эти функции могут выполнять фильтрацию, агрегацию, преобразования данных и многое другое в зависимости от ваших потребностей.', 'Например, если вы хотите провести анализ тональности текстовых сообщений из потока данных, вы можете разработать пользовательскую функцию обработки, используя библиотеки для обработки естественного языка (Natural Language Processing, NLP) как nltk или spaCy. Вот пример такой функции:', 'Эта функция analyze_sentiment анализирует тональность текста с использованием SentimentIntensityAnalyzer из nltk. Затем она может быть применена к DStream для анализа тональности сообщений в реальном времени.', 'Разработка пользовательских функций обработки позволяет настроить процесс под ваши конкретные потребности.', 'После обработки данных в потоке важно правильно хранить результаты, чтобы они были доступны для анализа, долгосрочного хранения или предоставления внешним системам. В этом разделе мы рассмотрим, как использовать хранилища данных для хранения результатов и почему NoSQL базы данных часто являются предпочтительным выбором в контексте реального времени.', 'Использование хранилищ данных для хранения результатов', 'После обработки данных в реальном времени, результаты могут быть разнообразными: агрегированные показатели, обогащенные данные, аналитические выводы и многое другое. Чтобы эффективно управлять этими результатами, часто используются различные хранилища данных:', 'Базы данных: Реляционные (SQL) и NoSQL базы данных могут использоваться для хранения обработанных данных. Реляционные базы данных, такие как PostgreSQL или MySQL, обеспечивают сильную структуру данных, в то время как NoSQL базы данных, такие как MongoDB или Cassandra, предоставляют гибкость и масштабируемость.', 'Хранилища ключ-значение: Такие хранилища, как Redis или etcd, предоставляют быстрое хранение и извлечение данных по ключу. Они особенно полезны для кэширования или быстрого доступа к результатам.', 'Хранилища данных в виде файлов: Файловые системы и облачные хранилища (например, Amazon S3) могут использоваться для долгосрочного хранения данных, а также для обмена данными между разными компонентами системы.', 'Пример сохранения результатов в реляционной базе данных с использованием библиотеки SQLAlchemy в Python:', 'Преимущества NoSQL баз данных для реального времени', 'В контексте реального времени, NoSQL базы данных часто предпочтительны по следующим причинам:', 'Гибкость схемы данных: NoSQL базы данных позволяют хранить данные без строгой схемы, что особенно полезно, когда формат данных может изменяться или когда необходима быстрая адаптация.', 'Горизонтальное масштабирование: Многие NoSQL базы данных обеспечивают горизонтальное масштабирование, что позволяет обрабатывать высокий объем данных в режиме реального времени.', 'Высокая производительность: NoSQL базы данных, такие как Apache Cassandra или Amazon DynamoDB, спроектированы для обеспечения высокой производительности при записи и чтении данных, что важно для реального времени.', 'Поддержка больших объемов данных: NoSQL базы данных могут легко обрабатывать большие объемы данных, что часто требуется при работе с потоками данных в реальном времени.', 'Гибридные решения: Некоторые NoSQL базы данных, например, Apache Cassandra, поддерживают гибридные модели данных, позволяя комбинировать SQL и NoSQL запросы для более сложных сценариев.', 'Хранение результатов обработки данных в реальном времени является ключевой частью пайплайна и позволяет обеспечить доступность и целостность данных для анализа и использования в вашем приложении. Выбор правильного хранилища данных зависит от ваших требований и характеристик вашего проекта.', 'Создание Kafka-топиков:', 'Первым шагом в построении пайплайна обработки данных в реальном времени с использованием Apache Kafka является создание необходимых топиков. Топики - это категории данных, в которые будут публиковаться и извлекаться данные. Для примера давайте создадим топик с именем "real-time-data".', 'Настройка потоков данных с Apache Kafka:', 'Теперь мы настроим потоки данных с помощью Apache Kafka. Мы будем использовать библиотеку Kafka-Python для создания производителя и потребителя.', 'Пример создания производителя для публикации данных в топик "real-time-data" с использованием Kafka-Python:', 'Пример создания потребителя для чтения данных из топика "real-time-data" с использованием Kafka-Python:', 'Обработка данных в потоке:', 'Теперь, когда у нас есть поток данных из Kafka, мы можем разработать обработчики данных с использованием Python. Допустим, вы хотите агрегировать данные из потока. Вот пример агрегации данных с использованием библиотеки pandas:', 'Этот код агрегирует данные по времени и выводит результаты.', 'Хранение данных:', 'Для хранения данных в реальном времени вы можете использовать базы данных, такие как Apache Cassandra или MongoDB, в зависимости от ваших требований. Например, вы можете сохранять агрегированные данные в базу данных Cassandra:', 'Далее, вы можете использовать Cassandra для сохранения агрегированных данных в реальном времени.', 'Мониторинг данных:', 'Мониторинг данных в пайплайне обработки данных в реальном времени критически важен. Вы можете использовать инструменты мониторинга, такие как Prometheus и Grafana, для отслеживания производительности Kafka-кластера, обработки данных и состояния системы в целом.', 'Пример настройки мониторинга с Prometheus и Grafana:', 'Настроить Prometheus для сбора метрик Kafka и ваших обработчиков данных.', 'Использовать Grafana для создания дашбордов и визуализации данных мониторинга.', 'Мониторинг поможет вам быстро обнаруживать проблемы и улучшать производительность вашего пайплайна обработки данных.', 'Построение пайплайна обработки данных с использованием Python и Apache Kafka представляет собой мощное решение для обработки и анализа данных в реальном времени. От выбора источников данных до оптимизации и масштабирования вашей системы, каждый этап играет решающую роль в обеспечении эффективной работы. ', 'В завершение хочу порекомендовать вам бесплатный вебинар от коллег из OTUS по теме: "Apache Spark Python API". Регистрация доступна по ссылке.', '', 'Пользователь', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}, {'header': 'Как настроить сбор статистики и автоматическое отключение пользователей WireGuard в ispmanager с помощью Python и API', 'text': ['Меня зовут Вячеслав, и я руководитель отдела маркетинга. Я поднял VPN-туннель по подписке на базе ispmanager. Ispmanager поддерживает WireGuard, который разворачивается за пару кликов. Минимум головной боли. Однако мне этого было мало: нужно было, чтобы по окончании подписки туннель автоматически отключался и статистика по каждому пользователю собиралась ежедневно. Панель по умолчанию предоставляет только суммарное количество использованного трафика по каждому пользователю, что тоже неплохо, но для моих целей не подходит.', 'У меня нет опыта самостоятельной разработки, кодинга и работы с консолью. Поэтому всё, что я дальше буду описывать, — это мои мытарства в попытке получить нужный результат. Все работы проводятся с помощью Python.', 'Задачи преследовал две:', 'Если пользователь перестал потреблять ресурсы, значит, он скоро отвалится или уже отвалился, и нужно с ним работать.', 'Если у пользователя закончилась подписка, она должна автоматически отключаться.', 'Немного матчасти ispmanager', 'Управление изнутри сервера – утилита mgrctl', 'Управление снаружи сервера – API-запросы', 'Логика работы скрипта', 'Рекомендации по сбору скрипта', 'Этап 0. Настройка Google Sheets', 'Этап 1. Подключение Google Sheets и библиотек Python', 'Этап 2. Получение пользователей WireGuard из ispmanager', 'Этап 3. Передача статистики в Google Sheets', 'Этап 4. Автоматическое отключение пользователей WireGuard через mgrctl', 'Этап 5. Загрузка и запуск сприпта на Python в ispmanager', 'Установка Python', 'Создание виртуального окружения', 'Установка библиотек и запуск', 'Резюме', 'Управлять без интерфейса (работать с API) в ispmanager можно несколькими путями: изнутри сервера и снаружи. В ситуации, когда скрипт расположен на сервере, разработчики рекомендуют использовать утилиту mgrctl, которая управляет панелью. При этом запрос к утилите всегда выглядит одинаково:', '/usr/local/mgr5/sbin/mgrctl -m ispmgr [функция] [команда],', 'где -m ispmgr означает, что обращаемся мы именно к ispmanager, а не к фреймворку coremanager, на котором написана панель.', 'Например, если мы хотим получить информацию обо всех возможностях mgrctl, надо в shell закинуть команду /usr/local/mgr5/sbin/mgrctl -m ispmgr -i. В ответ получим довольно длинный список возможных функций, но без описания параметров.', 'Второй вариант работы с ispmanager без интерфейса — это API-запросы. В официальной документации есть огромная статья с описанием большинства возможных функций. В соседней статье мы узнаем, что для любого взаимодействия по API нужна авторизация. Собственно, как и везде. Авторизоваться можно несколькими способами:', 'С использованием уникального номера сессии — подходит, когда нужно много работать с API. В первый раз получаем номер сессии и в последующем отправляем не пароль, а номер.', 'Через Authinfo — нужен для разового взаимодействия, когда в одном запросе передаются и логин, и пароль.', 'Сквозная авторизация по ключу — нужна для подключения из других систем. Как правило, чтобы автоматически авторизовать клиента в ispmanager. Для нашей ситуации совсем не подходит.', 'В документации деталей больше. В этой статье мы будем использовать Authinfo.', 'Среди доступных методов у нас GET и POST, а также возможность задавать формат вывода для результата запроса.', 'Перед тем как начать ковыряться с Python и API, я решил прописать логику работы скрипта.', 'Повторим задачи:', 'Собирать ежедневную статистику потребления трафика по каждому пользователю.', 'Отключать пользователей, если подписка закончилась.', 'Чтобы это провернуть, нам нужно:', 'Куда-то складывать статистику.', 'Где-то хранить данные о сроках действия подписок и о пользователях.', 'Сначала я было ткнулся в платные решения, но на текущем уровне развития проекта получалось шибко дорого. Поэтому что? Правильно — любимые Google Sheets, они подходят под обе задачи.', 'В ispmanager пользователи VPN хранятся в виде таблицы, значит, для наших задач нужно было сравнивать список пользователей ispmanager и список пользователей в Google Sheets. В итоге получилась следующая схема:', 'Небольшое отступление: сервис со временем развился, и появился второй протокол, помимо WireGuard. Из-за него гипотетически возможна ситуация, когда пользователь будет в таблице, но его не будет в ispmanager.', 'Строчек кода получается не очень много, но в любом случае, рекомендую обкладывать всё дебагом. Перед запуском вы всегда успеете его почистить, но подробный дебаг даст вам сильно больше информации о том, что вообще происходит в скрипте в тот или иной момент.', 'Кроме того, поскольку в скрипте я использую и API-запросы, которые можно отправлять с локальной машины, и вызов функции mgrctl, которую нужно делать изнутри сервера, целесообразно вначале разбить скрипт на несколько файлов и тестировать их отдельно друг от друга. Когда всё будет готово, просто соберёте один файл на сервере.', 'Если у вас возникнут сложности с ispmanager, не стесняйтесь писать ребятам в техподдержку. Они отвечают быстро и по делу. Писать скрипт за вас они бесплатно не будут. При необходимости, есть платные профсервисы, которые помогают с системным администрированием и настройкой сервера. Но вот разобраться с панелью или помочь запустить скрипт смогут легко и бесплатно.', 'Для начала подготовим Google Sheets. Логика скрипта предполагает размещение статистики на ежедневной основе. Поэтому нам понадобится таблица, где в первом столбце перечислены пользователи, а в первой строчке дни месяца.', 'Чтобы статистика была нагляднее, мы можем сделать автособираемую таблицу. Для этого:', 'Заполните все столбцы и строки любыми цифрами, позже там появится статистика потреблённого трафика.\xa0', 'Выделите получившийся массив.', 'Нажмите Вставка -> Диаграмма.', 'У вас автоматически соберётся что-то подобное:', 'Далее вы убираете все добавленные ранее цифры и спокойно ждёте. Когда скрипт отработает, графики будут строиться автоматически.', 'График потом можно будет унести стандартными средствами на другую страницу, чтобы он не мешал в таблице.', 'На Хабре довольно много статей, как с помощью Python попасть в Google Sheets. Сейчас я кратко обрисую, как и что делать. Если вам потребуется ещё информация, рекомендую статьи, по которым учился сам:', 'Начинаем работу с Google Sheets на Python. От регистрации до чтения данных\xa0', 'Генерируем красивую Google-таблицу из своей программы (используя Google Sheets API v4)', 'Во-первых, вам понадобится библиотека gspread. У неё нормально описанная документация, в случае необходимости можно обращаться к ней. Устанавливается через pip3 install gspread.', 'Во-вторых, вам понадобится файл credits.json, именно он будет обеспечивать подключения к таблицам.\xa0', 'Для этого:', 'Переходим в Google Cloud Console.', 'Нажимаем Create project и создаём проект.', 'Проваливаемся в настройки через троеточие в конце строки и переходим в раздел сервисных аккаунтов.', 'Создаём сервисный аккаунт, во втором пункте ставим роль «Владелец».', 'После создания двойным кликом проваливаемся внутрь аккаунта и переходим во вкладку «ключи». Добавляем новый ключ в формате json. На компьютер скачался файл, это и есть нужный нам credits.json.', 'Вверху страницы в поле поиска вбиваем sheets, выбираем Google Sheets API, проваливаемся внутрь и жмём кнопку «Подключить». Аналогично делаем для Google Drive.', 'Теперь копируем почту сервисного аккаунта и даём ей редакторский доступ в нужную нам таблицу.', 'У таблицы есть spreadsheetId, который имеет вид 1DuFovkpm-QXKHYHFHHEP3fojkkiN8sU9ngHTWhaY555. Его берём прямо из URL таблицы, это значение между /d/ и /edit.', 'С этим разобрались. Теперь, когда нам потребуется подключить гугл-таблицу в скрипт, мы можем сделать это командами:', 'WireGuard был новой фичей, и развёрнутую документацию по API подвезти ещё не успели. Но! Как показала практика, в вопросе API ispmanager можно было обойтись и без документации. В одной из статей документации говорится, что можно закинуть в shell команду tail -f /usr/local/mgr5/var/ispmgr.log | grep Request, потом выполнить в другом окне браузера в панели нужное действие и увидеть, что происходит под капотом. А в логе вы увидите что-то вроде того, что на скриншоте ниже.', 'Поскольку мы работаем с WireGuard, я сходил в соседнюю вкладку, выключил, а потом включил пользователя. В логе мы увидим получение таблицы с пользователями, выключение и включение пользователя.', 'Теперь из выделенной записи соберём части запроса: нам нужно всё, что после имени пользователя, удаляем лишнюю информацию вроде out=xjson&tconvert=undefined и двигаемся в сторону API.', 'Добавим к уже готовому коду из предыдущего пункта обработку XML. Это нужно, чтобы обрабатывать ответы, полученные по API от ispmgr. Для работы с XML я использовал модуль etree.', 'Import xml.etree.ElementTree as ET', 'Для понимания дальнейшей логики работы с XML рекомендую немного почитать, как строятся файлы в этом формате. Если коротко, все XML-файлы имеют древовидную структуру, похожую на структуру блоков в HTML, вроде:', 'Добавим библиотеку для работы с API-запросами', 'Import requests', 'Формируем запрос согласно документации и полученной от панели информации. Мне нужно обратиться один раз, поэтому я буду использовать authinfo.', 'Res = requests.request(‘get’, ‘https://IP:1500/ispmgr?authinfo=admin:password&func=wireguard.user&xml=out’)', 'Мы получили список пользователей ispmgr. Если вы дальше поставите команду', 'print(res.text)', 'увидите, что вам прислала панель. Если не ставить приставку .text, то вы увидите только код ответа, но не увидите его содержание.', 'Дальше нам необходимо обработать эту информацию. А именно: понять, сколько трафика использовал каждый пользователь, и записать эту информацию в Google Sheets.', 'Чтобы записывать в нужную ячейку, необходимо на уровне скрипта автоматически узнавать, какая сейчас дата. Для этого подключим модуль работы с датами и заведём дату в переменную.', 'Далее подключимся к нужной нам странице в таблице и получим столбец с именами пользователей. Для ускорения работы скрипта уберём из списка заголовок, для работы он нам не нужен.', 'Настало время обработать всё, что мы насобирали. Строим XML-дерево из полученного строкового списка, который хранится у нас в переменной res.', 'Root = ET.fromstringlist(res)', 'Теперь начинаем искать нужные нам данные. Каждый пользователь будет заведён через верхний уровень elem, поэтому перебираем циклом все elem, которые лежат на верхнем уровне дерева.', 'For elem in root.findall(‘elem’):', 'Далее нужно найти объём переданного трафика для найденного elem:', 'Sentsize = elem.find(‘sentsize’).text', 'Результат этого действия мы получим в формате Х.XX GB, что не подойдёт для построения графика: помешает размерность и точка в значении. Поэтому кусок с размерностью нужно удалить из строки, а точку заменить запятой.', 'После этого нам нужно узнать, что это за пользователь вообще.', 'Name = elem.find(‘name’).text', 'И теперь через цикл внутри цикла нужно перебрать все значения имён пользователей из гугл-таблицы, чтобы найти нужное и подставить туда полученные значения. Дополнительно мы введём три переменные i = индекс текущего цикла, a = координата a и b = координата b. Первая строчка у нас — даты месяца, а первый столбик — список имён. Значит, от них нужно будет отступить одну клетку.', 'Возникает логичный вопрос, зачем каждый раз обращаться к странице в таблице, если мы её уже подключили, когда брали пользователей. Но иначе при втором проходе цикл попытается вставить старые координаты, и вы получите ошибку о том, что координат больше, чем должно быть. Я пока не очень понял, почему получается именно так, но без повторного обращения к листу таблицы вылезает ошибка. Если есть идеи, буду рад услышать их в комментариях.', 'Одну задачу мы выполнили, осталась вторая — отключать юзеров, когда у них закончилась подписка.\xa0', 'Сразу оговорюсь, можно отключать пользователей через API и через mgrctl. Я погружался в API впервые, поэтому использовал оба метода. Но можно остановиться и на одном, более подходящем под ваши задачи.', 'Mgrctl — утилита, и запустить её напрямую из Python не выйдет, потому что нет библиотек. Но вы можете использовать подпроцесс. Для начала нужно подключиться к той таблице и листу, где у вас лежат пользователи и срок действия их лицензий. Я не ограничиваю пользователей по трафику, поэтому нужно следить только за сроком. Плюс я использую ту же таблицу, поэтому просто подключаюсь к другому листу.', 'Worksheet = sh.worksheet(“worksheet_name”)', 'Если порядок пользователей отличается от порядка на этапе статистики, необходимо снова получить их список и убрать заголовок.', 'Ещё нам нужно получить даты действия лицензий.', 'Далее формируем цикл, в котором сравниваем даты действия лицензии из таблиц и текущую дату. Предварительно импортируем модуль подпроцессов, поскольку он понадобится внутри цикла, а также заводим индекс выполнения цикла.', 'Дата, которую мы получили из гугл-таблиц, представляет собой текстовую строку. Когда мы заходим сравнить отдельные её части через .moth или .day, сделать это не получится. Поэтому нужно изменить строку в готовый для сравнения вид.', 'Дальше происходит непосредственно сравнение. Для нас важны две ситуации:', 'Порядковое число месяца окончания лицензии больше, чем у текущего месяца. Если этого не проверять, рискуем отключить лицензии, продлённые на срок больше месяца.', 'Порядковое число дня окончания лицензии больше, чем у текущего дня.', 'Кроме этого, важно помнить, что для отключения пользователя нам нужно обращаться к mgrctl, а значит, нужно строкой передать данные. Но в подпроцесс у меня не получилось добавить переменную, только захардкоженную строку, хотя вроде как технически это возможно. А без переменной мы не сможем передать, какого конкретно пользователя отключить, без перебора всех вариантов.', 'Хорошая новость в том, что подпроцесс умеет использовать переменную для запуска подпроцесса. А значит, мы можем в переменную добавить другую переменную, которая учтётся при её формировании. Осталось только монитор присобачить…\xa0', 'Построим условия для ситуаций и обработку отключений пользователей.', "Появились ещё две непонятные надписи: ' sok=ok' и shell=True. Первая эмулирует нажатия кнопки «ОK» на форме подтверждения, которая выскакивает после попытки отключить юзера. Вторая говорит, что подпроцесс нужно выполнять в shell, это не очень безопасно, но подходит, когда нужно передать строку в url, чем мы, собственно и занимаемся.", 'Когда скрипт готов, дело за малым — запустить его внутри ispmanager. Если вы планируете запускать скрипт с другого сервера, этот этап смело пропускайте. Я же использую mgrctl, складывать скрипт нужно на сервер, где установлен ispmanager.', 'Ispmanager поддерживает обработку Python, но предварительно её надо включить в конфигурации ПО.', 'Теперь панель поддерживает обработку Python. Как запустить сайт на нём, описано в документации. Но нам не нужен сайт, поэтому идём дальше.', 'Для запуска нашего скрипта необходимо создать виртуальное окружение — место, куда будут устанавливаться все нужные нам библиотеки. Я использую Python версии 3.11, поэтому разворачиваю такое же окружение. Для этого в shell-клиенте ispmanager нужно выполнить команду:', '/opt/ispmanager/python3.11/bin/python3.11 -m venv <имя-вашего-окружения>', 'Чтобы работать с окружением, необходимо его активировать:', 'source <имя-вашего-окружения>/bin/activate', 'Внутри окружения работает pip и pip3, но есть нюанс. Библиотека gspread и так довольно вредная в установке, тут отказалась заводиться. Помогло прямое обращение к интерпретатору Python в следующем формате:', '<имя-вашего-окружения>/bin/python3.11 pip3 install gspread', 'Важно: предварительно надо прожать f5, находясь на экране shell, чтобы выйти из окружения. Остальные модули установились через стандартные pip и pip3 внутри окружения.', 'После того как все модули установлены, можно загружать скрипт. Для этого идём в Менеджер файлов и складываем в нужную нам папку файл скрипта с расширением .py и файл credits.json, которые мы достали из Google. Я подключал логирование, поэтому рядом со скриптом положил файл и для него. Тоже с расширением .py. Складывать файлы в одну папку необязательно.\xa0', 'Сохраняем путь до файла и возвращаемся в shell. Чтобы запустить файл, нужно воспользоваться командой:', '<имя-вашего-окружения>/bin/python3.11 <путь до файла>', 'Если всё сделано правильно, запуск пройдёт удачно, а в консоли ничего не будет видно. Но зато будет видно в Google Sheets. Если у вас другая версия Python поменяйте 3.11 на нужный интерпретатор.', 'Если есть пользователи, подпадающие под критерии, на вкладке VPN в ispmanager они тоже отключатся.', 'Я сознательно не стал убирать кусок с API-запросом, чтобы показать разные варианты взаимодействия с ispmanager. Но поскольку скрипт лежит на сервере с панелью, можно и запрос пользователей переписать на mgrctl. Если решите переписывать, не забудьте, что вывод из subprocess не передаётся в Python по умолчанию, его необходимо подхватывать с помощью отдельной команды.', 'По ходу работы я добавлял много дебага в код, причём по привычке командой print. Вам советую пользоваться модулем logging: он умеет писать в файл за пределами скрипта, что важно, когда программа выполняется в фоновом режиме.', 'Работа над статьёй помогла сделать код чище, но всё ещё возможна лишняя нагрузка на оперативку — сказывается моя неопытность в общем написании кода. Если у вас остались вопросы или появились советы по улучшению, буду рад обсудить их в комментариях.', 'А если статья была полезна, ставьте плюсик. Пусть больше людей увидят материал.', '', 'Руководитель отдела маркетинга', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}, {'header': 'Как правильно писать API авто тесты на Python', 'text': ['Эта статья как продолжение статьи Как правильно писать UI авто тесты на Python. Если мы говорим про UI автотесты, то тут хотя бы есть паттерны Page Object, Pagefactory; для API автотестов таких паттернов нет. Да, существуют общие паттерны, по типу Decorator, SIngletone, Facade, Abstract Factory, но это не то, что поможет протестировать бизнес логику. Когда мы пишем API автотесты, то нам хотелось бы, чтобы они отвечали требованиям:', 'Проверки должны быть полными, то есть мы должны проверить статус код ответа, данные в теле ответа, провалидировать JSON схему;', 'Автотесты должны быть документированными и поддерживаемыми. Чтобы автотесты мог читать и писать не только QA Automation, но и разработчик;', 'Хотелось бы, чтобы JSON схема и тестовые данные генерировались автоматически на основе документации;', 'Отчет должен быть читабельным, содержав в себе информацию о ссылках, заголовках, параметрах, с возможностью прикреплять какие-то логи.', 'Для меня требования выше являются базой, ваши же требования могут быть другие в зависимости от продукта.', 'Также очень важно отметить, что если при написании автотестов вы выберете неправильный подход, то проблемы появляются не сразу, а примерно через 100-150 написанных тестов. Тогда фиксы автотестов превратятся в ад, добавление новых автотестов будет все сложнее и сложнее, а читать такие автотесты никто кроме вас не сможет, что плохо. В практике встречаются случаи, когда компания просит переписать их автотесты и очень часто мотивом является: “Наш QA Automation ушел, поэтому теперь мы не можем даже запустить автотесты и непонятно, что в них происходит”. Это означает, что человек, написавший автотесты, писал их костыльно, как бы повышая свою ценность (в плохом смысле, что никто, кроме него, не сможет понять автотесты в будущем после его ухода или банального ухода на больничный), как сотрудника, что очень плохо для компании. В итоге время потрачено, деньги потрачены.', 'Еще один распространенный кейс - это когда новый QA Automation приходит на проект и сразу же хочет все переписать. Окай, переписывает, суть не меняется, автоматизация также страдает. По "правильному" мнению человека, который все переписал, виноват продукт, разработчики, но не он сам. Компания в данном случае выступает тренажером/плейграундом для неопытного QA Automation. В итоге время потрачено, деньги потрачены.', 'Для примера написания API автотестов мы будем использовать:', 'pytest - pip install pytest;', 'httpx - pip install httpx, - для работы с HTTP протоколом;', 'allure - pip install allure-pytest, - необязательная зависимость. Вы можете использовать любой другой репортер;', 'jsonschema - pip install jsonschema, - для валидации JSON схемы;', 'pydantic, python-dotenv - pip install pydantic python-dotenv, - для генерации тестовых данных, для управления настройками, для автогенерации JSON схемы;', 'Почему не requests? Мне нравится httpx, потому что он умеет работать асинхронно и у него есть AsyncClient. Также документация httpx в стиле Material Design мне больше нравится, чем у requests. В остальном requests замечательная библиотека, можно использовать ее и  разницы никакой нет.', "Библиотека pydantic служит для валидации, аннотации, парсинга данных в python. Она нам нужна для автогенерации JSON схемы, для описания моделей данных, для генерации тестовых данных. У этой библиотеки есть много плюсов по сравнению с обычными dataclass-сами в python. Если приводить пример из жизни, то pydantic - это как ехать на автомобиле, а dataclass'ы - это идти пешком.\xa0", 'В качестве альтернативы pydantic можно взять библиотеку models-manager, которая делает все тоже самое, что и pydantic, т.е. умеет работать с базой данных из коробки, генерировать рандомные негативные тестовые данные на основе модели. Эта библиотека больше подойдет для тестирования валидации входных данных вашего API. Документацию по models-manager можно найти тут. Мы не будем использовать models-manager, так как нам не нужна база данных и мы не будем тестировать валидацию.', 'Но у pydantic тоже есть библиотека SQLModel для работы с базой данных. Если вам для автотестов нужна база данных, то вы можете использовать: SQLAlchemy + pydantic, SQLModel, models-manager. В нашем же случае работа с базой данных не потребуется.', 'Тесты будем писать на публичный API https://sampleapis.com/api-list/futurama. Данный API всего лишь пример. На реальных проектах API может быть гораздо сложнее, но суть написания автотестов остается та же. ', 'Опишем настройки проекта. Для этого будем использовать класс BaseSettings из pydantic_settings, потому что он максимально удобный, умеет читать настройки из .env файла, умеет читать настройки из переменных окружения, умеет читать настройки из .txt файла, умеет управлять ссылками на редис или базу данных и много чего еще, можно почитать тут https://docs.pydantic.dev/latest/concepts/pydantic_settings/. Это очень удобно для использования на CI/CD, или когда у вас есть много настроек, которые разбросаны по всему проекту + с BaseSettings все настройки можно собрать в один объект.', 'settings.py', 'Мы будем читать настройки из .env файла.', '.env', 'Обратите внимание на то, как записаны переменные окружения TEST_USER.EMAIL и TEST_USER.PASSWORD. Это сделано специально, чтобы "упаковать" значения во вложенную модель TestUser. В данном случае, в качестве разделителя используется точка, но это можно настроить с помощью параметра env_nested_delimiter=\'.\'', 'Теперь опишем модели, используя pydantic', 'Модель для аутентификации:', 'models\\authentication.py', 'Внутри метода validate_root мы проверяем, был ли передан токен или пользователь при инициализации объекта Authentication. Если не было передано ни того, ни другого, то мы выбрасываем ошибку', 'Напишем модель для объекта question из API https://sampleapis.com/api-list/futurama. Сам объект выглядит примерно так:', 'models\\questions.py', 'Обратите внимание на аргумент alias в функции Field. Он служит для того, чтобы мы могли работать со snake_case в python и с любым другим форматом извне. Например, в python нам бы не хотелось писать название атрибута таким образом - possibleAnswers, т.к. это нарушает PEP8, поэтому мы используем alias. Pydantic сам разберется, как обработать JSON объект и разобрать его по нужным атрибутам в модели. Так же в функции Field есть очень много крутых фич по типу: max_length, min_length, gt, ge, lt, le и можно писать регулярки. Есть куча полезных настроек для ваших моделей и есть возможность использовать встроенные типы или писать свои. Короче, пользуйтесь.', 'Данные функции: random_list_of_strings, random_number, random_string используются, чтобы сгенерировать какие-то рандомные данные. Мы не будем усложнять и напишем эти функции, используя стандартные средства python, в своих же проектах вы можете использовать faker.', 'utils\\fakers.py', 'Готово, мы описали нужные нам модели. С помощью них можно будет генерировать тестовые данные:', 'JSON схема генерируется автоматически на основе модели. В практике встречал людей, которые писали JSON схему руками, при этом считали это единственным верным подходом, но не нужно так. Ведь если объект состоит из 4-х полей, как в нашем случае, то еще можно написать JSON схему руками, а что если объект состоит их 30-ти полей? Тут уже могут быть сложности и куча потраченного времени. Поэтому мы полностью скидываем эту задачу на pydantic:', 'Теперь опишем базовый HTTP клиент, который будет использоваться для выполнения HTTP запросов, а также API клиент, который будет применяться для создания классов, с помощью, которых будем взаимодействовать с API тестируемой системы:', 'utils/clients/http/client.py', 'Мы создали свой класс HTTPClient, который унаследовали от httpx.Client и переопределили необходимые нам методы, добавив к ним allure.step. Теперь при http-запросе через HTTPClient в отчете у нас будут отображаться те запросы, которые мы выполняли. Мы специально использовали allure.step, как декоратор, чтобы в отчет также попали параметры, которые мы передаем внутрь функции метода. Позже посмотрим, как это все будет выглядеть в отчете. Внутрь HTTPClient мы также можем добавить запись логов или логирование в консоль, но в данном примере обойдемся только allure.step, на своем проекте вы можете добавить логирование.', 'Класс APIClient является базовым для взаимодействия с API системы. В нашем случае мы создаем классы AuthenticationClient и QuestionsClient, которые наследуются от APIClient. Важно подчеркнуть, что класс APIClient предназначен исключительно для взаимодействия с API и не имеет информации о среде, к которой он обращается, а также не знает о токенах и заголовках запросов. Все эти настройки определяются на уровне класса HTTPClient', 'Напишем билдер, который будет инициализировать класс HTTPClient:', 'utils/clients/http/builder.py', 'Мы создали функцию get_http_client, которая будет конструировать и возвращать объект HTTPClient. Эта функция будет добавлять базовые атрибуты, заголовки, base_url от которого будем строить ссылки на запросы к API. В этом API https://sampleapis.com/api-list/futurama нет аутентификации, я указал заголовок для аутентификации по API Key ради примера. Скорее всего на вашем проекте у вас будет другой заголовок для аутентификации. AuthenticationClient реализуем ниже', 'Теперь опишем методы для взаимодействия с API. ', 'Для примера опишем клиент, который будет работать с аутентификацией. Для https://sampleapis.com/api-list/futurama аутентификация не требуется, но в своем проекте вы можете указать ваши методы для получения токена.', 'base\\api\\authentication_api.py', 'Теперь опишем клиент для работы с API questions:', 'С помощью клиента QuestionsClient сможем выполнять простые CRUD запросы к API.', 'Добавим необходимые утилитки, которые помогут сделать тесты лучше:', 'utils\\constants\\routes.py', 'Лучше хранить роутинги в enum, чтобы не дублировать код и наглядно видеть, какие роутинги используются:', 'utils\\fixtures\\questions.py', 'Фикстура class_questions_client используется для инициализации клиента QuestionsClient. Скоуп специально выбран на класс, потому что не имеет смысла инициализировать данный клиент на каждый тест, возможно из-за специфики тестирования вашей системы, скоуп может быть другой', 'Для некоторых тестов, например, на удаление или изменение, нам понадобится фикстура function_question, которая будет создавать question. После создания мы будем возвращать объект DefaultQuestion и когда тест завершится, то удалим его delete_question_api(question.id).', 'Лайфхак. В названиях фикстур используется приставка class_<имя фикстуры> и function_<имя фикстуры>. Это не просто так – приставка соответствует скоупу действия фикстуры, который устанавливается с помощью параметра scope в pytest.fixture(scope="class"). Таким образом, мы включаем информацию о скоупе фикстуры прямо в её название. Это может быть полезно, когда вам нужны одни и те же фикстуры с разными скоупами в разных частях вашего кода.', 'Например, в некоторых случаях нам может потребоваться создавать нового пользователя для каждого теста, а в других – иметь одного пользователя для всего тестового класса. Используя такое разделение в названиях фикстур, мы делаем код более читабельным и избегаем неявных обозначений скоупов, которые могут ухудшить понимание кода', 'conftest.py', 'Не забудем включить наши фикстуры в pytest_plugins. Хотя в принципе вы можете создавать фикстуры непосредственно рядом с вашими тестами в файлах conftest, из моего опыта могу сказать, что это не долгоиграющая история. В реальных проектах бизнес-логика может быть гораздо сложнее, и фикстуры могут иметь иерархию или наследоваться друг от друга.', 'Например, для добавления пользователя в группу может потребоваться создать группу, затем создать пользователя и только после этого добавить пользователя в группу. Это означает, что у вас может возникнуть сложная иерархия фикстур и их наследование. При использовании отдельных conftest файлов вам могут понадобиться костыли для импортирования фикстур напрямую в эти файлы или сложная организация структуры тестов.', 'Чтобы избежать таких проблем и упростить жизнь себе и другим автоматизаторам, которые будут писать тесты вместе с вами или после вас, рекомендую использовать плагины pytest. Это позволяет более гибко и эффективно использовать фикстуры и организовывать их наследование', 'utils\\assertions\\schema.py', 'Функция validate_schema будет использоваться для валидации схемы. Можно было бы использовать validate из jsonschema, но тогда мы потеряем allure.step. ', 'Для проверок вы можете использовать обычный assert в python, либо же одну из библиотек: assertpy, pytest-assertions. Но мы будем использовать кастомную реализацию expect, которая будет включать в себя allure.step или другой удобный для вас репортер. Стоит отметить, что в библиотеке pytest-assertions также есть встроенные allure.step. ', 'Реализацию expect вы можете посмотреть тут https://github.com/Nikita-Filonov/sample_api_testing/tree/main/utils/assertions/base. По этой ссылке код достаточно объемный, поэтому я не буду разбирать его в статье. ', 'Также добавим функцию, которая будет проверять корректность объекта question, который вернуло на API.', 'utils\\assertions\\api\\questions.py', 'Эта функция служит для того, чтобы нам не приходилось в каждом тесте писать заново все проверки для объекта question и достаточно будет использовать функцию assert_question. Если у вас объект состоит из множества ключей (например, 20), то рекомендую писать такие обертки, чтобы использовать их повторно в будущем.', 'Также обратите внимание на QuestionDict - это не модель, это TypedDict и он служит для аннотации dict в python. Лучше стараться писать более конкретные типы вместо абстрактного dict, учитывая, что аннотации в python - это просто документация и не более. Ибо в будущем абстрактные аннотации будут только затруднять понимание кода. Даже если вы пишете просто тип int, то лучше писать что-то конкретное по типу MyScoreInt = int.', 'Мы подготовили всю базу для написания тестов. Осталось только написать сами тесты:', 'tests\\test_futurama_questions.py', 'Тут 5-ть тестов на стандартные CRUD операции для questions API https://api.sampleapis.com/futurama/questions. ', 'Возвращаясь к нашим требованиям: ', 'Проверяем статус код ответа, тело ответа, JSON схему;', 'При создании объекта внутри метода create_question у нас происходит автоматическая валидация на основе модели pydantic DefaultQuestion(**response.json()). Это автоматически избавляет нас от необходимости писать проверки для ответа API;', 'Автотесты документированы и легко читаются. Теперь другой QA Automation или разработчик, когда посмотрит на наши тесты, сможет увидеть аннотацию в виде моделей. Посмотрев на модели, он сможет легко разобраться с какими именно объектами мы работаем. В pydantic имеется возможность добавлять description к функции Field, поэтому при желании вы сможете описать каждое поле вашей модели;', 'JSON схема генерируется автоматически, рандомные тестовые данные тоже генерируются автоматически на основе модели. При большой мотивации вы можете взять ваш Swagger и вытащить из него JSON схему с помощью https://github.com/instrumenta/openapi2jsonschema. Далее y pydantic есть убойная фича https://docs.pydantic.dev/datamodel_code_generator/ и на основе JSON схемы pydantic сам сделает нужные модели. Этот процесс можно сделать автоматическим.', 'Запустим тесты и посмотрим на отчет:', 'Теперь запустим отчет:', 'Либо можете собрать отчет и в папке allure-reports открыть файл index.html:', 'Получаем прекрасный отчет, в котором отображается вся нужная нам информация. Вы можете модифицировать шаги под свои требования или добавить логирование для каждого HTTP запроса. ', 'Полную версию отчета посмотрите тут.', 'Весь исходный код проекта расположен на моем github.', 'Всегда старайтесь писать автотесты так, чтобы после вас их смог прочитать любой другой QA Automation или разработчик; желательно не только прочитать и понять, но и легко починить, если потребуется. Не повышайте свою ценность для компании через "магический код" понятный только вам.', 'UPD. Статья была обновлена, поскольку код из неё морально устарел. Кроме того, версия pydnatic была обновлена до версии 2.4, и в данной версии были устранены некоторые баги, которые ранее требовали использования костылей. Если вам интересно посмотреть на старую версию автотестов, вы можете найти её здесь', '', 'Пользователь', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}, {'header': 'Microsoft представила дополнение Python Editor от команды Excel Labs', 'text': ['Microsoft представила дополнение Python Editor от команды Excel Labs для расширенной и экспериментальной работы с языком программирования Python в Excel. Дополнение Python Editor позволяет вводить более длинный и сложный код в электронные таблицы и ячейки Excel.', 'Python Editor показывает ячейки с кодом Python в порядке выполнения в дополнение к выходным данным кода каждой ячейки, что может помочь в отладке и доработке листинга код. Это полезно, поскольку ячейки с кодом Python в сетке Excel выполняются в порядке следования строк.', 'Дополнение Python Editor поддерживает множество функций, включённых в инструментарий Microsoft Visual Studio Code для разработки Python: IntelliSense, code completion, форматирование и подсветку синтаксиса.', 'С помощью Python Editor разработчики могут написать некоторый код в ячейке, а затем они могут переключиться на другой элемент в приложении Excel. Далее разработчики могут вернуться и продолжать писать код в Python Editor в нужной ячейке до тех пор, пока он не будет отлажен как следует, а затем применить его в Excel.', 'Дополнение Python Editor доступно вместе с надстройкой Excel Labs. Пользователи Excel, у которых нет этой надстройки, могут перейти на вкладку «Вставка» Excel и затем нажать кнопку «Получить надстройки». Затем они могут выполнить поиск по запросу Excel Labs и нажать кнопку «Добавить» для установки надстройки.', '22 августа 2023 года Microsoft сообщила, что добавила в бета-версию Microsoft 365 язык программирования Python в Excel для улучшения возможности анализа и визуализации данных. Ограничения в рамках интеграции Python и Excel: запуск в облачной среде, использование защищённых библиотек, предоставленных Anaconda, запрет доступа к сети, запрет обращения к пользовательским токенам, код Python не будет иметь доступа к другим свойствам файла, таким как формулы, диаграммы, сводные таблицы, макросы или код VBA.', 'Информационная служба Хабра', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}, {'header': 'FIFO очередь asyncio в Python', 'text': ['Это перевод статьи об asyncio.Queue. Позже планирую дополнить тему статьями про asyncio.LifoQueue и asyncio.PriorityQueue. Я постарался дополнить перевод и исправить ошибки - в оригинале они были, но возможно что-то пропустил. Если вы нашли ошибку, пожалуйста, используйте Ctrl+Enter и я исправлю. Спасибо!', 'При написании приложений для обработки событий или данных других типов нам часто бывает нужен механизм для хранения событий и распределения их между несколькими исполнителями. Затем исполнители могут конкурентно сделать с этими событиями все, что нужно; это позволяет сэкономить немного времени по сравнению с последовательной обработкой событий.', 'Библиотека asyncio предоставляет для этой цели реализацию асинхронной очереди: asyncio.Queue для очереди типа FIFO, asyncio.PriorityQueue для приоритетных очередей и asyncio.LifoQueue для очереди типа LIFO.', 'Мы можем добавить в очередь данные и запустить несколько конкурентных исполнителей, которые будут извлекать данные из очереди и обрабатывать их по мере готовности. Такую схему работы часто называют производитель–потребитель(паттерн producer-consumer).  Одна сторона порождает данные или события, которые надлежит обработать; их обработка может занять длительное время. Очередь позволяет делегировать длительные операции фоновым задачам, сохранив отзывчивость пользовательского интерфейса. Мы помещаем элемент в очередь для последующей обработки и информируем пользователя, что работа началась в фоне.', 'У асинхронных очередей есть и дополнительное преимущество – они дают механизм ограничения конкурентности, поскольку обычно с очередью работает конечное число задач-исполнителей.', 'Из книги "Asyncio и конкурентное программирование на Python" Мэттью Фаулера', 'В этом уроке вы узнаете, как обмениваться данными между корутинами с помощью asyncio.Queue в Python. ', 'asyncio.Queue предоставляет FIFO-очередь для использования с корутинами, но прежде чем мы погрузимся в детали работы asyncio.Queue, давайте рассмотрим очереди в общем виде в Python.', 'Queue(очередь) - это структура данных, в которую элементы могут быть добавлены вызовом put() и извлечены вызовом метода get(). Python предоставляет потокобезопасную очередь с помощью класса queue.Queue, который позволяет потокам обмениваться объектами друг с другом.', 'Модуль queue реализует очереди с несколькими производителями( multi-producer) и потребителями(multi-consumer). Он особенно полезен в потоковом программировании, когда требуется безопасно обмениваться информацией между несколькими потоками. Класс Queue этого модуля реализует всю необходимую семантику блокировки.', ' Queue – A synchronized queue class', 'Безопасная для процессов очередь обеспечивается с помощью класса multiprocessing.Queue. Эта очередь является одновременно потокобезопасной и процессобезопасной и позволяет процессам совместно использовать данные Python-объектов.', 'Обе очереди управляют данными в порядке очереди FIFO, что означает, что элементы извлекаются из очереди в том порядке, в котором они были добавлены. Первые элементы, добавленные в очередь, будут получены первыми. Это противоположно другим типам очередей, таким как очередь "последний в очереди" и "первый из очереди", а также приоритетным очередям.', 'Далее рассмотрим очередь asyncio.', 'В Python асинхронные очереди - это тип структуры данных, в которой элементы могут храниться и извлекаться в порядке поступления (FIFO). Они предназначены для использования с корутинами - функциями, которые могут быть приостановлены и возобновлены асинхронно. Для создания очередей asyncio необходимо использовать класс asyncio.Queue.', 'Очередь asyncio.Queue не является ни потокобезопасной, ни процессоробезопасной. Это означает, что она не может использоваться потоками или процессами для совместного использования объектов Python и предназначена только для использования корутинами в рамках одного потока Python, например, одного цикла событий.', 'asyncio.Queue предназначен для использования в asyncio-программах в виде корутин, поэтому некоторые методы этого класса фактически являются корутинами и должны использовать вместе await. Это означает, что asyncio.Queue не может быть использован вне asyncio-программы. ', 'Очереди в asyncio могут быть использованы для:', 'Реализация веб-краулеров, которые параллельно получают и анализируют веб-страницы.', 'Построение брокеров сообщений, распределяющих задачи между несколькими рабочими.', 'Разработка чат-приложений, которые асинхронно отправляют и получают сообщения.', 'Напишите свой вариант в комментариях)', 'await queue.put(item) - для помещения элемента в очередь. Если очередь переполнена, этот метод будет ждать, пока не освободится свободный слот.', 'await queue.get() - для получения элемента из очереди. Если очередь пуста, этот метод будет ждать, пока элемент не станет доступен.', 'queue.task_done() - для индикации того, что ранее полученный элемент был обработан. Этот метод должен вызываться потребительскими корутинами после завершения работы с элементом.', 'await queue.join() - для блокировки обработки всех элементов в очереди. Этот метод должен вызываться корутинами-производителями после того, как они завершат занесение элементов в очередь.', 'Можно также использовать некоторые "некорутинные" методы очереди, например:', 'queue.put_nowait(item) - чтобы поместить элемент в очередь без блокировки. Если очередь переполнена, этот метод вызовет исключение QueueFull.', 'queue.get_nowait() - для получения элемента из очереди без блокировки. Если очередь пуста, то этот метод вызовет исключение QueueEmpty.', 'queue.qsize() - для получения количества элементов в очереди.', 'queue.empty() - для проверки, пуста ли очередь.', 'queue.full() - для проверки заполнения очереди.', '', 'В этом разделе мы рассмотрим примеры использования класс asyncio.Queue, включая создание и настройку экземпляра, добавление и удаление элементов, запросы к свойствам очереди и управление задачами.', 'Мы можем создать asyncio.Queue, создав экземпляр этого класса. По умолчанию очередь не будет ограничена по вместимости. Например:', 'asyncio.Queue принимает один аргумент конструктора - "maxsize", который по умолчанию равен нулю (без ограничений). Например:', 'Мы можем установить ограничение на размер очереди. Эффект ограничения размера означает, что когда очередь заполнена и корутины пытаются добавить объект, они блокируются до тех пор, пока не освободится место, или терпят неудачу, если используется неблокирующий метод. Поскольку аргумент "maxsize" является первым позиционным аргументом, не обязательно указывать его по имени. Например:', 'Объекты Python могут быть добавлены в очередь с помощью метода put(). На самом деле это корутина, которой необходимо ожидать. Причина этого заключается в том, что вызывающая корутина может заблокироваться, если очередь переполнена. Например:', 'Элемент также может быть добавлен в очередь без блокировки с помощью метода put_nowait(). Этот метод не является корутиной и либо добавляет элемент, либо возвращается немедленно, либо выдает исключение asyncio.QueueFull, если очередь переполнена и элемент не может быть добавлен.', 'Элементы могут быть получены из очереди путем вызова метода get(). На самом деле это корутина, которой необходимо ожидать(await). Причина заключается в том, что в очереди может не быть элементов для получения в данный момент, и вызывающая корутина должна блокироваться до тех пор, пока элемент не станет доступным.', 'Извлеченный элемент будет самым старым из добавленных, если типа очереди  FIFO. Элемент может быть получен из очереди без блокировки с помощью метода get_nowait(). Этот метод не является корутиной и вернёт элемент немедленно, если он доступен, в противном случае произойдет сбой с исключением asyncio.QueueEmpty. Например:', 'Мы можем получить фиксированный размер очереди через свойство "maxsize". Например:', 'Проверить, пуста ли очередь, можно с помощью функции empty(), которая возвращает True, если очередь не содержит элементов, и False в противном случае. Например:', 'Мы также можем проверить, заполнена ли очередь, с помощью метода full(), который возвращает True, если очередь заполнена, и False в противном случае. Например:', 'Элементы в очереди могут рассматриваться как задачи, которые могут быть помечены потребительскими(consumer) корутинами как процессы.', 'Этого можно добиться, если потребительские корутины будут извлекать элементы из очереди с помощью get() или get_nowait() и после обработки помечать их методом task_done(). Например:', 'Другие программы могут быть заинтересованы в том, чтобы узнать, когда все элементы, добавленные в очередь, будут получены и помечены как выполненные. Этого можно добиться, если программа ожидает выполнения программы join() в очереди.', 'Корутина join() не вернется, пока все элементы, добавленные в очередь до ее вызова, не будут помечены как выполненные.', 'Например:', 'Если очередь пуста или все элементы уже помечены как выполненные, то корутина join() возвращается немедленно. Теперь, когда мы знаем, как использовать asyncio.Queue, давайте рассмотрим несколько работающих примеров.', 'Рассмотрим использование класса asyncio.Queue на рабочем примере. В этом примере мы создадим корутину-производителя, которая будет генерировать десять случайных чисел и помещать их в очередь. Также будет создана корутина-потребитель, которая будет получать числа из очереди и сообщать их значения. asyncio.Queue обеспечивает возможность обмена данными между этими производящей и потребительской корутинами.', 'Во-первых, мы определим функцию, которая будет выполняться корутиной-производителем. Задача будет выполнять десять итераций в цикле. На каждой итерации будет генерироваться новое случайное значение от 0 до 1 с помощью функции random.random(). Затем она будет спать в течение доли секунды для имитации работы, после чего поместит значение в очередь. После завершения задачи она поместит в очередь значение None, чтобы сигнализировать корутине-потребителю об отсутствии дальнейшей работы. Приведенная ниже программа producer() реализует это, принимая в качестве аргумента экземпляр очереди.', 'Далее мы можем определить функцию, которую будет выполнять корутину-потребитель. Задача будет циклически повторяться. На каждой итерации она будет получать элемент из очереди и блокировать его, если он еще не доступен. Если элемент, полученный из очереди, имеет значение None, то задача прервет цикл и завершит работу программы. В противном случае печатается значение. Приведённая ниже корутина consumer() реализует это и принимает в качестве аргумента экземпляр очереди.', 'Наконец, в основной программе мы создаём экземпляр общей очереди. Затем мы создаём  и запускаем корутины производителя и потребителя и дожидаемся их завершения с помощью метода asyncio.gather()', 'При запуске этой прогарммы сначала создаётся общий экземпляр asyncio.Queue. Затем создаётся корутина producer, которой передается экземпляр очереди. Затем запускается корутина-потребитель, а главная корутина main() блокируется до тех пор, пока не завершатся обе корутины.', 'Кораутина-производитель генерирует новое случайное значение для каждой итерации задачи, блокирует и добавляет его в очередь. Кораутина-потребитель ожидает поступления элементов в очередь, затем потребляет их по одному, сообщая их значение. Наконец, задача-производитель завершается, в очередь помещается значение None, и работа программы завершается. Кораутин-потребитель получает значение None, прерывает свой цикл и также завершает работу.', 'Это наглядно показывает, как можно использовать asyncio.Queue для удобного обмена данными между "производящими" и "потребительскими" корутинами. Обратите внимание, что вывод программы будет отличаться при каждом запуске, поскольку в ней используются случайные числа.', '', 'Далее рассмотрим, как можно получить значения из очереди без блокировки.', 'Мы можем получать значения из очереди asyncio.Queue без блокировки. Это может быть полезно, если мы хотим использовать занятое ожидание в корутине-потребителе для проверки другого состояния или выполнения других задач в ожидании поступления данных в очередь.  Мы можем обновить пример из предыдущего раздела, чтобы получать элементы из очереди без блокировки. Этого можно добиться, вызвав метод get_nowait(). Функция get_nowait() возвращается немедленно. ', 'Если в очереди есть значение, которое необходимо получить, то оно возвращается. В противном случае, если очередь пуста, возникает исключение asyncio.QueueEmpty, которое может быть обработано. В данном случае, если нет значения, которое можно получить из очереди, мы сообщаем об этом и засыпаем на долю секунды. Затем мы выполнение программы продолжится, что приведёт к возврату к началу цикла ожидания занятости потребителя.', 'Запуск примера создает общую очередь.Queue, затем, как и прежде, запускает корутины consumer и producer. Корутина-производитель генерирует, блокирует и добавляет элементы в очередь. Корутина-потребитель пытается получить значение из очереди. Если значение не получено, то возникает исключение asyncio.QueueEmpty, которое обрабатывается путем выдачи сообщения, "сна" на доли секунды и повторного запуска цикла ожидания.', 'В противном случае, если в очереди есть значение, потребитель получит его и сообщит об этом в обычном режиме. Мы видим, что сообщения от корутины-потребителя заняты ожиданием поступления новых данных в очередь. Это показывает, как можно получать элементы из asyncio.Queue без блокировки. Обратите внимание, что вывод программы будет отличаться при каждом запуске, поскольку в ней используются случайные числа.', '', 'Далее рассмотрим, как можно получить значения из очереди с таймаутом.', 'Мы можем получать значения из очереди asyncio.Queue с помощью блокировки, но с ограничением по таймауту. Это позволяет потребительской корутине не только блокировать ожидание поступления значений в очередь, но и выполнять другие задачи во время ожидания. Это может быть более эффективно, чем занятое ожидание без каких-либо блокирующих вызовов.', 'Мы можем обновить приведенный выше пример, чтобы использовать таймаут при получении элементов из очереди в корутине-потребителе. Этого можно добиться, вызывая корутину get() как обычно. ', 'В отличие от queue.Queue, asyncio.Queue не поддерживает тайм-аут напрямую. Вместо этого мы можем обернуть корутину get() в корутину wait_for(), которая поддерживает таймаут. Если таймаут истекает до завершения работы корутины get(), то возникает исключение asyncio.TimeoutError, которое может быть обработано. Например:', 'Запуск примера создает общую очередь asyncio.Queue, затем, как и прежде, запускает корутины consumer и producer. Корутина-производитель будет генерировать, блокировать и добавлять элементы в очередь. Корутин-потребитель попытается получить значение из очереди. Она блокируется на время таймаута. Если до истечения тайм-аута значение не будет получено, то возникнет исключение asyncio.TimeoutError, которое будет обработано путем выдачи сообщения и повторного запуска цикла ожидания. В противном случае, если в очереди есть значение, потребитель получит его и сообщит об этом в обычном режиме.', 'Мы видим, что сообщения от корутины-потребителя заняты ожиданием поступления новых данных в очередь. Здесь показано, как получать элементы из asyncio.Queue с помощью блокировки по таймауту.  Обратите внимание, что вывод программы будет отличаться при каждом запуске, поскольку в ней используются случайные числа.', '', 'Далее рассмотрим, как можно ожидать в очереди и помечать задачи как завершенные в очереди.', 'В предыдущих примерах мы посылали в очередь специальное сообщение (None), чтобы указать, что все задачи выполнены. Альтернативный подход заключается в том, чтобы заставить корутины ждать непосредственно в очереди, а корутину-потребителя помечать задачи как выполненные. Этого можно добиться с помощью функций join() и task_done() в asyncio.Queue. Обновим нашу программу. ', 'Корутина-producer может быть обновлена, чтобы больше не посылать в очередь значение None, указывающее на отсутствие дальнейших задач. Корутина-consumer может быть обновлена, чтобы больше не проверять сообщения None и помечать каждую задачу как выполненную с помощью вызова task_done(). ', 'Корутина-producer будет работать до тех пор, пока в очередь не перестанут добавляться задачи, и завершится. Корутина-consumer теперь будет работать вечно. Сначала мы запустим корутину-потребителя как отдельную самостоятельную задачу. Затем мы выполним и будем ожидать выполнения корутины-производителя до тех пор, пока она не будет завершена и все элементы не будут добавлены в очередь.', 'Наконец, мы будем ждать, пока все добавленные в очередь элементы не будут помечены как выполненные. Давайте посмотрим на эту программу:', 'Запуск программы создает общую очередь asyncio.Queue, затем, как и прежде, запускает корутины consumer и producer. Корутина-производитель генерирует, блокирует и добавляет элементы в очередь. Корутина-потребитель пытается получить значения из очереди. После того как корутина-производитель добавит все свои десять элементов, она завершится. Корутина-потребитель будет работать вечно в фоновом режиме. После завершения работы корутины-производителя главная корутина main() блокирует очередь. После того как корутина-потребитель обработает все элементы, добавленные в очередь, корутина main() возобновит работу и завершится. После этого программа завершается, а корутина-потребитель продолжает работать в фоновом режиме, но уже без обработки. ', 'Здесь было показано, как отмечать задания в очереди как выполненные и как ждать в очереди завершения всех работ. Обратите внимание на то, что вывод программы будет отличаться при каждом запуске, поскольку в ней используются случайные числа.', '', 'Далее рассмотрим, как можно работать с очередью ограниченного размера.', 'Мы можем ограничить ёмкость очереди. Это может быть полезно при наличии большого числа производителей или медленных потребителей. Это позволяет ограничить количество задач, которые могут находиться в памяти в каждый момент времени, ограничивая общее использование памяти приложением. Этого можно добиться, задав аргумент "maxsize" в конструкторе очереди при ее настройке. Поскольку это первый и единственный позиционный аргумент, мы можем не указывать его имя в конструкторе.', 'Когда очередь заполнена, вызов функции put() будет блокироваться до тех пор, пока не освободится место для размещения очередного элемента в очереди. Обновим пример из предыдущего раздела, чтобы ограничить размер очереди небольшим числом, например 2 элемента, и чтобы скромное число производителей, например 5, пыталось заполнить очередь. Это позволит держать очередь заполненной большую часть времени, вынуждая производителей блокировать ее при добавлении элементов.', 'Во-первых, мы можем задать ёмкость очереди при ее построении.  Далее мы можем создать пять корутин-производителей, которые будут одновременно добавлять в очередь задачи с попытками выполнения. Это можно сделать в виде списка, который затем можно распаковать на отдельные выражения в вызове asyncio.gather().', 'После того как все производители завершат свою работу, корутина main() может присоединиться к очереди и ждать, пока потребитель отметит все элементы как выполненные.', 'При запуске этого примера сначала запускается корутина-потребитель, затем все пять корутин-производителей. Затем  корутина main() блокируется до завершения работы корутин-производителей. Затем каждая из пяти корутин-производителей пытается добавить в очередь десять элементов настолько быстро, насколько это возможно. Емкость очереди настолько ограничена, что эти программы большую часть времени будут блокировать вызов функции put(), пока не освободится место для добавления нового элемента в очередь. Корутина-потребитель будет потреблять элементы из очереди так быстро, как только сможет, сообщать их значения и помечать их как выполненные. Она будет работать вечно в качестве фоновой задачи.', 'После завершения работы коуртин-произвиотелей корутина main() возобновляет работу и блокирует очередь, ожидая, пока все оставшиеся задачи будут потреблены и помечены как выполненные корутиной-потребителем.', 'В этом примере было показано, как использовать ограниченную емкость asyncio.Queue и как сочетать это с пометкой задач как выполненных и присоединением к очереди. Обратите внимание, что вывод программы будет отличаться при каждом запуске, поскольку в ней используются случайные числа.', '', 'Вот мои книги и другие материалы по\xa0asyncio:', 'Python Asyncio Jump-Start', 'Python Asyncio Interview Questions', 'Asyncio Module API Cheat Sheet', 'Вот — книги других авторов:', 'Python Concurrency with asyncio', 'Using Asyncio in Python', 'asyncio — Asynchronous I/O', 'Asyncio Coroutines and Tasks', 'Asyncio Streams', 'Asyncio Subprocesses', 'Asyncio Queues', 'Asyncio Synchronization Primitives', 'Asynchronous I/O, Wikipedia', 'Coroutine, Wikipedia', '', '', 'Ищу работу', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}, {'header': 'Microsoft добавила Python в Excel', 'text': ['22 августа 2023 года Microsoft сообщила, что добавила в бета-версию Microsoft 365 язык программирования Python в Excel для улучшения возможности анализа и визуализации данных.', '«Вы можете манипулировать данными и анализировать информацию в Excel с помощью графиков и библиотек Python, а затем использовать формулы, диаграммы и сводные таблицы Excel для дальнейшего уточнения своих идей. Теперь вы можете выполнять расширенный анализ данных в удобной среде Excel, получая доступ к Python прямо из ленты Excel», — пояснил генеральный менеджер Microsoft Стефан Киннестранд.', 'Видео с возможностью использования Python в Exel.', 'В Microsoft пояснили, что пользователям теперь не нужно больше устанавливать какое-либо дополнительное программное обеспечение или настраивать надстройку для доступа к функциональным возможностям, поскольку интеграция Python в Excel будет частью встроенных соединителей Excel и Power Query. Microsoft также добавляет новую функцию PY, которая позволяет отображать данные Python в сетке электронной таблицы Excel. Благодаря партнёрству с Anaconda (корпоративному репозиторию Python), популярные библиотеки Python, такие как pandas, statsmodels и Matplotlib, будут доступны в Excel в скором времени всем пользователям Microsoft 365.', '«Я рад, что эта превосходная тесная интеграция Python и Excel теперь увидела свет. Я ожидаю, что оба сообщества найдут новые интересные применения в этом сотрудничестве, расширив возможности каждого партнёра. Когда я присоединился к Microsoft три года назад, я и представить себе не мог, что такое возможно», — пояснил создатель Python Гвидо ван Россум, который с ноября 2020 года является заслуженным и действительным инженером в Microsoft.', 'Microsoft пояснила, что Python в Excel будет включён в подписку на Microsoft 365 во время предварительного тестирования новой версии продукта, но «некоторые его функции будут ограничены без доступа по платной лицензии» после окончания процесса внутреннего тестирования.', 'Ограничения в рамках интеграции Python и Excel: запуск в облачной среде, использование защищённых библиотек, предоставленных Anaconda, запрет доступа к сети, запрет обращения к пользовательским токенам, код Python не будет иметь доступа к другим свойствам файла, таким как формулы, диаграммы, сводные таблицы, макросы или код VBA.', 'Информационная служба Хабра', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}, {'header': 'Год ожиданий — и мы получили Python 3.12. Изменения, новшества и дополнения', 'text': ['Пользователь', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}, {'header': 'JetBrains и Python Software Foundation рассказали, как разработчики использовали Python в 2022 году', 'text': ['JetBrain совместно с Python Software Foundation опубликовали результаты большого исследования, помогающего понять, как разработчики использовали Python в 2022 году. Исследование строится на базе опроса разработчиков. В 2022 году в нём приняло участие более 23 тыс. человек из почти 200 регионов.', 'Результаты исследования:', 'разработчики на Python в 86% случаев используют его вместе с другими языками и технологиями. В пятёрку популярных входят JavaScript, HTML/CSS, SQL, Bash/Shell и C/C++;', '51% опрошенных использует язык для работы и собственных проектов, ещё 28% использует только для образования и реализации собственных идей и 21% — только на работе;', 'в основном Python используется для анализа данных, веб-разработки, машинного обучения, DevOps и разработки веб-парсеров;', 'более 90% разработчиков перешли на Python 3, а старой версией пользуется всего 7%;', 'чаще всего Python устанавливается и обновляется с официального сайта, пакетных менеджеров в ОС (apt-get, yum, homebrew и других), Anaconda, Docker и pynew;', 'для изоляции среды Python используют Virtualenv, Docker, Conda, Pipenv и Poetry. Важно отметить, что в 2022 году популярность Poetry значительно выросла среди разработчиков;', 'тройку популярных веб-фреймворков на Python представляют Flask, Django и FastAPI;', 'пятёрку популярных библиотек на Python представляют Requests, Pillow, Asyncio, Tkinter и PyQT;', 'для тестирования чаще всего используют pytest, unittest и mock;', 'в качестве CI-систем разработчики выбирают GitHub Actions, Gitlab CI и Jenkins;', 'самый популярный редактор кода — VS Code, а PyCharm отстаёт на 8%;', '59% опрошенных постоянно работают с Python на работе, 13% используют язык для обучения, 7% — фрилансеры.', 'Более детально результаты исследования можно изучить на официальном сайте проекта.', '', 'Информационная служба Хабра', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}, {'header': 'Вышел Python 2.7.18, последний релиз ветки Python 2.x', 'text': ['Информационная служба Хабра', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}, {'header': 'Полноценный 2D-платформер на Python в 2023? Мой опыт', 'text': ['Говорят, что на Python легко и просто создавать платформеры. Правда ли?', 'Все мы были когда-то детьми. И те, кто вырос в 90-ые, наверняка играли в приставку Денди (в США она называлась NES - Nintendo Entertainment System). Среди всех игр была одна игра, которая мне особенно запомнилась, так как была не похожа на все остальные. Это игра The Addams Family (1992 год, студия Ocean). В игре была какая-то своя атмосфера.\xa0И мне захотелось создать что-то похожее.', 'Сюжет в игре будет очень простым: мы купили поместье викторианской эпохи, и когда туда приехали, нам очень сильно захотелось заснуть. При этом мы обратили внимание, что повсюду разбросаны детали некоторого механизма. Проблема в том, что дверь в поместье закрыта и нам надо найти ключи. Ходим ищем ключи от дверей, собирая детали, а когда открываем двери ищем кровать, чтобы поспать. Видим очень странные сны, в которых также собираем предметы, уклоняясь от врагов и шипов. И в конце находим проблему этого поместья.', 'Перед тем как приступить к созданию ассетов (разных картинок, которые потом можно будет анимировать), надо разобраться в каком разрешении будет работать игра. У всех разные мониторы с разным разрешением. И не у всех даже FullHD. Поэтому выбираем 720p - то есть разрешение 1280х720 пикселей. Для такого разрешения органично будут смотреться плитки земли размером 64х64 пикселя. Берем любой векторный графический редактор и начинаем рисовать.', 'Рисовал как мог, вспоминая как у всех ребят в школе по рисованию было «5», и только у меня одного «4». Вы могли заметить, что это все статические объекты, которые не имеют анимации. Ну а как же с анимированными объектами? Все просто, анимированные объекты - это те же отдельные картинки, у которых изменяется положение некоторых пикселей. Вот пример анимации на примере главного героя игры:', 'Инструмент для создания игр мы будем выбирать на основании того языка программирования, который более-менее знаем. В моем случае, это Python. Выбираем какую-нибудь современную версию языка - я выбрал Python 3.11.4. Для создания игр на Python существует библиотека Pygame. Причем это не графический движок типа Unity. Здесь нет графического интерфейса, а есть только набор разных классов, в которых есть свои атрибуты и методы. Эта библиотека служит для осуществления манипуляции графическими объектами на основе событий (events).', 'Игру начинаем даже не с файла main.py, \xa0а с файла settings.py, куда будут прописаны основные параметры и настройки игры. Помимо названия игры, длины и ширины окна игры, мы должны прописать доступы к ассетам. В связи с тем, что данных много, а в Python есть такой тип данных как словарь (dict), в основе которого лежит хеш-таблица, мы выбираем именно словарь и заполняем. Фрагмент такого словаря:', 'Наконец-то поработаем с main.py. Конечно, будем использовать нашу любимую концепцию ООП. Есть такая штука как принципы SOLID, которым следует придерживаться при разработке программы. Некоторые из них я собираюсь нарушить, но вот один я никак нарушить не могу - буковка “S” - Single Resposibility Principle. Суть его в том, что каждый класс должен выполнять строго обозначенную функцию и быть ограниченным своей задачей. Не надо создавать классы, которые делают все сразу. Поэтому main.py будет класс Main, в котором есть главный цикл игры - бесконечный цикл с условием While, но все события будут обрабатываться в других отдельных классах, а в Main мы будем создавать экземпляры этих других классов.', 'Как думаете, что объединяет такие игры как Heroes of Might and Magic 3, The Elder Scrolls III: Morrowind и Max Payne. Их объединяет, что на диске с ними шел встроенный редактор уровней. Это мощнейший инструмент в разработке игры. Беда в том, что в Pygame ничего подобного нет, а значит мы его сами создадим. Здесь лучше найти какой-нибудь туториал. Я лично нашел на YouTube видео немецкого программиста Christian Koch “Creating a Mario Maker style game in Python” (канал ClearCode). На основе этого видео и создаем редактор уровней. Но нам надо как-нибудь сохранять те произведения искусства, которые мы создали. И здесь у нас есть выбор: либо сохранять как текстовый формат передачи данных (например, JSON), или же сохранять в бинарном виде, используя библиотеку pickle. Я решил, что для уровней у нас будут бинарные файлы, а для сохранений в процессе игры у нас будет JSON. ', 'Параллельно с режимом редакторов уровней у нас есть отдельный класс Level, в экземпляр которого будут передаваться данные из редактора. И все механики будут тестироваться в именно в экземпляре класса Level.', 'Спрайт в Pygame - \xa0это графическое изображение, которое представляет собой одну единицу анимации. Главное здесь - это коллизии и анимации. С коллизиями все просто - у классов Pygame есть встроенные методы для работы с коллизиями, например, collidepoint. Для анимаций в соответствующем классе мы создадим свой метод и используем тернарный оператор:', 'Мы просто перебираем картинки в списке, и вызываем их одну за другой с помощью переменной self.frame_index. Тернарый оператор применяется, чтобы из бежать ошибки IndexError: list index out of range.', 'Обратите внимание на константу ANIMATION_SPEED. Дело в том, что у нас разлочен FPS в игре и скорость анимации никак не зависит от FPS.', 'Не помню какой обзорщик из YouTube 10-ых годов говорил, что главное меню - это как вешалка в театре. Для меня очень удобным было меню из игры The Elder Scrolls V: Skyrim - ничего лишнего. Нечто похожее и мы сделаем с учетом, что я не умею рисовать и игру мы делаем на Pygame. В главном меню мы должны сказать игроку как управлять персонажем в игре и создать возможности поменять язык, перейти в полноэкранный режим, уменьшить или увеличить громкость музыки и звуков, и перейти в режим редактора. ', 'Если для звуков полно бесплатных ресурсов, где можно скачать free sounds, то музыку я решил сам написать для игры. Все рождается из импровизации. Записываем все на листочек, а потом ноты перебиваем в любой музыкальный midi-редактор, который поддерживает нотный стан.', 'Вот пример трека Garden из моей игры:', 'Как видно, самый обычный соль-мажор и нисходящие, восходящие гармонии. Остается все это записать на своем синтезаторе Casio из детства, немного обработать и саундтрек готов.', 'Самое главное, что я понял, создание игры - это хорошая возможность прокачать ваши hard skills. Процесс создания игры заставляет вас решать множество задач. Библиотека Pygame - это один из самых лучших способов понять концепцию ООП в Python. Я, когда неправильно прописал условия для звуков и музыки, понял, как именно загружаются в память компьютера экземпляры классов, как в них инициализируются атрибуты и как работают методы. Также вы повторите весь базовый синтаксис Python - работу со всеми типами данных, включая файлы, и со стандартными библиотеками типа math, random, configparser, json и pickle.', 'Полный код игры доступен на моем GitHub', 'На GitHub разблочен режим редакторов уровней и имеет полный функционал, а в архиве с игрой этот функционал ограничен в плане рисования и сохранений.', '', 'Пользователь', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}, {'header': 'Три уровня погружения в Python. Запись докладов с Python Meetup и полезные материалы', 'text': ['Привет, Хабр! В сентябре мы провели Selectel Python Meetup на тему «Три уровня погружения: процессы под капотом, архитектура кода, развитие языка». Разработчики из Selectel и Райффайзенбанка рассказали о сборе метрик и мониторинге, проектировании микросервисной архитектуры, изменениях в Python и о том, что ждет язык в будущем. Записи докладов и материалы с предыдущего митапа — под катом.  ', 'Смотрите весь митап целиком или переходите к отдельным докладам. В конце каждого выступления спикеры отвечают на вопросы участников. ', 'Спикер:\xa0Никита Моторный, разработчик в Selectel', 'Доклад о том, как построить мониторинг без сюрпризов. Рассматриваем ситуацию, когда авторы flask-prometheus-exporter не подружились с форкающимся gunicorn и отказались от сбора процессных метрик. Углубляемся в примитивы и технические дебри библиотеки. А еще разбираемся, какой набор процессов использует gunicorn и какие метрики дает ядро linux.\xa0', 'Смотреть доклад про мультипроцессность → ', 'Спикер:\xa0Александр Шишебаров, старший разработчик в Selectel', 'Рассказываем, какие подводные камни ждут вас при проектировании нового сервиса в большой распределенной инфраструктуре. Что стоит предусмотреть при проектировании микросервисной архитектуры на примере глобального роутера в облаке Selectel. А именно: как выстроить взаимодействие компонентов в Kubernetes и вне, как организовать сбор метрик, чтобы потом не страдать.\xa0', 'Смотреть доклад про микросервисы → ', 'Спикер:\xa0Денис Аникин, тимлид в Райффайзенбанке', 'Рассуждаем о причине популярности Python и стараемся ответить на вопрос «К чему язык и экосистема Python придут через несколько лет?» Рассказываем про изменения Python и и актуальные PEPы, вспоминаем Language summit, доклады, статьи и экспертные мнения.', 'Смотреть доклад про будущее Python →', 'Типизация в Python. Работа с Mypy, PyCharm и SQLAlchemy 2.0', 'Как и зачем у нас появился статический анализатор типов для Python', 'Как сделать бота для заказа шавермы и оставить голодными лишь 1,1% коллег', 'Как создать мод для Cyberpunk 2077 и какие инструменты выбрать', '', 'Пользователь', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}, {'header': 'Python: Построение графиков по данным из файла', 'text': ['Когда я был ВУЗ(овцем) нам на первом курсе на лабораторных работах по Физике часто приходилось строить графики. Причем рисовать их приходилось от руки на миллиметровой бумаге. Выглядело это кустарно. С первого раза начертить график не получалось. Приходилось стирать ластиком. Миллиметровая шкала стиралась. На графике появлялись белые облака.', 'Тогда в 200x просто не хватало навыков программирования чтобы отрисовать эти графики на PC. Сейчас же построить график можно с легкостью на LapTop(е). Причем существует целая куча разных способов построить график на PC. Это можно делать в Google Spreadsheets, MatLab, MathCAD, GNU Octave, GNU Plot, MS Excel, GraphViz, Asymptote. ', 'Попробуем еще построить график на Python при помощи программного компонента matplotlib.', 'Постановка задачи:', 'Есть файл LiLog.csv.  Вот несколько его строчек:', 'Надо построить 2D график, где по оси Х n-ный столбец, а по оси Y - k-тый столбец из текстового файла.', 'Что надо из софтвера?', '№', 'Программа', 'Назначение', '1', 'Python.exe', 'Интерпретатор язык программирования Python', '2', 'matplotlib', 'Модуль для визуализации', '3', 'csv', 'Модуль синтаксического разбора *.CSV файлов', '4', 'NotePad++.exe', 'Текстовый редактор для написания Python скрипта и редактирования файла с исходными данными для графика', 'Решение', 'Вот этот скрипт берет *.csv файл и строит график по 4му и 2му столбцу.', 'Что происходит в этом скрипте. Программа создает 2 списка: X Y. В список X помещает числа из 4го столбца в список Y помещает данные из второго столбца. Затем программа отрисовывает график по этим значениям на канве в отдельном окне.', 'Получился вот такой график', 'Также в график можно добавить еще один график, пояснения (легенду).', 'Чтобы это код исполнился надо предварительно в консоли прописать', 'Вот, например, для наглядности добавлена прямая порогового значения для данного измерения на уровне 63 Люкс.', 'График в matplotlib не просто статический. Его можно увеличивать в интересующем месте и  подставить поля графика в меню, которое расположено в нижнем левом углу окна. ', 'Достоинства построения графиков на Python', 'Это бесплатно. В отличие от MatLab, MathCAD в Python вы можете строить графики абсолютно бесплатно.', 'Есть аналитика. Можно увеличивать график, сохранять график в формате *.png файла, задавать масштаб, подстраивать ширину полей, разворачивать шкалу, накладывать сетку.', 'По Python скрипту можно сгенерировать *.exe файл на случай, если захочется скрыть алгоритм построения графика.', 'Нет артефактов и временных файлов. Никаких *.o *.ld не нужно, как если бы вы решили писать графопостроитель на С++. Есть только *.py файл с исходником и больше ничего не нужно.', 'Всё делается чисто кодом. Вам даже мышка не нужна чтобы построить график. Не будет болеть запястье.', 'Благодаря Python можно исполнять скрипты в любой операционной системе: Windows, Linux и проч. Главное чтобы был интерпретатор Python и графическая оболочка.', 'Недостатки построения графиков в Python', 'Не совсем ясно как отображать отсчеты графика в реальном времени. Например когда числа поступают с улицы из последовательного COM пота или TCP сокета.', 'Вывод', 'Интерпретатор Python в связке с Matplotlib  это отличный вариант для визуализации экспериментальных данных из текстового *.csv файла.', 'Акроним', 'Расшифровка', 'CSV ', 'Comma-Separated Values  ', 'PC', 'personal computer', 'Links', 'https://translated.turbopages.org/proxy_u/en-ru.ru.769a89e5-64b314a2-b8a40da2-74722d776562/https/www.geeksforgeeks.org/how-to-plot-data-from-a-text-file-using-matplotlib/', '', 'Embedded SW/Firmware Engineer', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}, {'header': 'Python как компилируемый статически типизированный язык программирования', 'text': ['По данным широко известного в узких кругах Tiobe Index язык Python скорее всего станет языком 2020 года, в четвертый раз в своей карьере. Кроме того, скорее всего он обгонит Java и займет вторую строчку в общем рейтинге языков программирования вслед за языком C.', 'Основным драйвером роста популярности языка Python стало его широкое использование в задачах машинного обучения. Но как же так? Python динамически типизируемый и интерпретируемый язык. Это же все очень медленно. Как его использовать в научных вычислениях, которые требуют максимальной производительности.', 'Обычно считается, что Python это только обертка над вычислительным ядром, написанным на C++.  А что еще можно ожидать от такого медленного языка? Но ядро то ядром, но местами хочется обработать данные здесь и сейчас на таком удобном Python.', 'За всю историю Python было придумано большое количество решений, позволяющих ускорить Python код: a) Fortran, C, C++ модули; b) NumPy массивы; c) Cython расширения, и много другого. Это все работало, конечно, но все это было лишь внешним кодом по отношению к Python. Местами довольно неуклюжим.', 'А что собственно можно еще было сделать? Для быстрого кода нужны типы. А потом, все это как-то надо было комплировать в рамках интерпретируемого языка. Звучит как-то не очень реально. Но! Это все работает, прямо сейчас. ', 'Две дороги: python аннотации типов и LLVM jit компиляция сошлись в релизе Numba 0.52.0. Смотрим на код, который говорит сам за себя.', 'Каждый класс компилируется с помощью LLVM в нативный код платформы с использованием аннотаций типов.', 'Добро пожаловать в строго типизированный компилируемый Python!', 'Пользователь', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}, {'header': 'В начале этого года Python сместил Java и стал вторым по популярности языком программирования среди разработчиков', 'text': ['Аккаунт компании', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}, {'header': 'Есть ли будущее у Python? Обсудим в этот четверг', 'text': ['28 сентября мы проведем Selectel Python Meetup на тему «Три уровня погружения: процессы под капотом, архитектура кода, развитие языка».\xa0Разработчики из Selectel и Райффайзенбанка расскажут о сборе метрик и мониторинге, проектировании микросервисной архитектуры, изменениях в Python и о том, что ждет язык в будущем. Приходите лично или подключайтесь к трансляции. Подробнее — под катом. ', 'Мультипроцессность и сбор метрик в Python: как построить мониторинг без сюрпризов', 'Авторы flask-prometheus-exporter не подружились с форкающимся gunicorn и отказались от сбора процессных метрик. Что делать, если эти метрики вам очень нужны? Мы решили углубиться в примитивы и технические дебри библиотеки. А еще разобрались, какой набор процессов использует gunicorn и какие метрики дает ядро linux. Что получилось — расскажу в докладе.', 'Разработчик, Selectel', 'Заносим микросервисы и Kubernetes в облако ', 'Спроектировать новый сервис в большой распределенной инфраструктуре? Легко (нет)! Вас ждут подводные камни и ограничения.\xa0Я расскажу, что стоит предусмотреть при проектировании микросервисной архитектуры на примере нашего глобального роутера в облаке. А именно: как выстроить взаимодействие компонентов в Kubernetes и вне, как организовать сбор метрик, чтобы потом не страдать. Ну и конечно, поделюсь собственными ошибками и выводами.', 'Старший разработчик, Selectel', 'Такое ли светлое будущее у Python? ', 'Что стало причиной такой популярности Python? Простота или то, что третья версия поменяла язык целиком? И самое главное — куда язык идет?\xa0Расскажу об изменениях Python: обозначу позицию языка в backend разработке, расскажу о новинках и порассуждаю, к чему язык и экосистема Python придут через несколько лет. Буду опираться на ту базу, которая закладывается в язык прямо сейчас, рассказывать про актуальные PEPы, вспоминать Language summit, доклады, статьи и экспертные мнения.', 'Тимлид, Райффайзенбанк', 'Приходите на\xa0живую встречу\xa0в офис Selectel.\xa0Регистрируйтесь онлайн, и мы пришлем ссылку на просмотр. ', '', 'Пользователь', '\n          Ваш аккаунт\n        ', '\n          Разделы\n        ', '\n          Информация\n        ', '\n          Услуги\n        ']}]